{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Matchbox \u00b6 Matchbox is a service that matches bare-metal machines to profiles that PXE boot and provision clusters. Machines are matched by labels like MAC or UUID during PXE and profiles specify a kernel/initrd, iPXE config, and Ignition config. Features \u00b6 Chainload via iPXE and match hardware labels Provision Fedora CoreOS or Flatcar Linux (powered by Ignition ) Authenticated gRPC API for clients (e.g. Terraform) Installation \u00b6 Matchbox can be installed from a binary or a container image. Install Matchbox as a binary , as a container image , or on Kubernetes Setup a PXE-enabled network Tutorials \u00b6 Start provisioning machines with Fedora CoreOS or Flatcar Linux. Terraform Usage Fedora CoreOS (live PXE or PXE install to disk) Flatcar Linux (live PXE or PXE install to disk) Local QEMU/KVM Fedora CoreOS (live PXE or PXE install to disk) Flatcar Linux (live PXE or PXE install to disk) Related \u00b6 dnsmasq - container image to run DHCP, TFTP, and DNS services terraform-provider-matchbox - Terraform provider plugin for Matchbox Typhoon - minimal and free Kubernetes distribution, supporting bare-metal","title":"Home"},{"location":"#matchbox","text":"Matchbox is a service that matches bare-metal machines to profiles that PXE boot and provision clusters. Machines are matched by labels like MAC or UUID during PXE and profiles specify a kernel/initrd, iPXE config, and Ignition config.","title":"Matchbox"},{"location":"#features","text":"Chainload via iPXE and match hardware labels Provision Fedora CoreOS or Flatcar Linux (powered by Ignition ) Authenticated gRPC API for clients (e.g. Terraform)","title":"Features"},{"location":"#installation","text":"Matchbox can be installed from a binary or a container image. Install Matchbox as a binary , as a container image , or on Kubernetes Setup a PXE-enabled network","title":"Installation"},{"location":"#tutorials","text":"Start provisioning machines with Fedora CoreOS or Flatcar Linux. Terraform Usage Fedora CoreOS (live PXE or PXE install to disk) Flatcar Linux (live PXE or PXE install to disk) Local QEMU/KVM Fedora CoreOS (live PXE or PXE install to disk) Flatcar Linux (live PXE or PXE install to disk)","title":"Tutorials"},{"location":"#related","text":"dnsmasq - container image to run DHCP, TFTP, and DNS services terraform-provider-matchbox - Terraform provider plugin for Matchbox Typhoon - minimal and free Kubernetes distribution, supporting bare-metal","title":"Related"},{"location":"api-grpc/","text":"gRPC API \u00b6 Protos \u00b6 rpc.proto storage.proto Client Libraries \u00b6 gRPC client libraries Go Client Plugins \u00b6 terraform-provider-matchbox","title":"gRPC API"},{"location":"api-grpc/#grpc-api","text":"","title":"gRPC API"},{"location":"api-grpc/#protos","text":"rpc.proto storage.proto","title":"Protos"},{"location":"api-grpc/#client-libraries","text":"gRPC client libraries Go","title":"Client Libraries"},{"location":"api-grpc/#client-plugins","text":"terraform-provider-matchbox","title":"Client Plugins"},{"location":"api-http/","text":"HTTP API \u00b6 iPXE script \u00b6 Serves a static iPXE boot script which gathers client machine attributes and chainloads to the iPXE endpoint. Use DHCP/TFTP to point iPXE clients to this endpoint as the next-server. GET http://matchbox.foo/boot.ipxe GET http://matchbox.foo/boot.ipxe.0 // for dnsmasq Response #!ipxe chain ipxe?uuid=${uuid}&mac=${mac:hexhyp}&domain=${domain}&hostname=${hostname}&serial=${serial} Client's booted with the /ipxe.boot endpoint will introspect and make a request to /ipxe with the uuid , mac , hostname , and serial value as query arguments. iPXE \u00b6 Finds the profile for the machine and renders the network boot config (kernel, options, initrd) as an iPXE script. GET http://matchbox.foo/ipxe?label=value Query parameters Name Type Description uuid string Hardware UUID mac string MAC address * string Arbitrary label Response #!ipxe kernel /assets/coreos/1967.3.0/coreos_production_pxe.vmlinuz coreos.config.url=http://matchbox.foo:8080/ignition?uuid=${uuid}&mac=${mac:hexhyp} coreos.first_boot=1 coreos.autologin initrd /assets/coreos/1967.3.0/coreos_production_pxe_image.cpio.gz boot GRUB2 \u00b6 Finds the profile for the machine and renders the network boot config as a GRUB config. Use DHCP/TFTP to point GRUB clients to this endpoint as the next-server. GET http://matchbox.foo/grub?label=value Query parameters Name Type Description uuid string Hardware UUID mac string MAC address * string Arbitrary label Response default=0 timeout=1 menuentry \"CoreOS\" { echo \"Loading kernel\" linuxefi \"(http;matchbox.foo:8080)/assets/coreos/1967.3.0/coreos_production_pxe.vmlinuz\" \"coreos.autologin\" \"coreos.config.url=http://matchbox.foo:8080/ignition\" \"coreos.first_boot\" echo \"Loading initrd\" initrdefi \"(http;matchbox.foo:8080)/assets/coreos/1967.3.0/coreos_production_pxe_image.cpio.gz\" } Cloud config \u00b6 DEPRECATED: Finds the profile matching the machine and renders the corresponding Cloud-Config with group metadata, selectors, and query params. GET http://matchbox.foo/cloud?label=value Query Parameters Name Type Description uuid string Hardware UUID mac string MAC address * string Arbitrary label Response #cloud-config coreos : units : - name : etcd2.service command : start - name : fleet.service command : start Container Linux Config / Ignition Config \u00b6 Finds the profile matching the machine and renders the corresponding Ignition Config with group metadata, selectors, and query params. GET http://matchbox.foo/ignition?label=value Query parameters Name Type Description uuid string Hardware UUID mac string MAC address * string Arbitrary label Response { \"ignition\" : { \"version\" : \"2.0.0\" }, \"systemd\" : { \"units\" : [{ \"name\" : \"example.service\" , \"enable\" : true , \"contents\" : \"[Service]\\nType=oneshot\\nExecStart=/usr/bin/echo Hello World\\n\\n[Install]\\nWantedBy=multi-user.target\" }] } } Generic config \u00b6 Finds the profile matching the machine and renders the corresponding generic config with group metadata, selectors, and query params. GET http://matchbox.foo/generic?label=value Query parameters Name Type Description uuid string Hardware UUID mac string MAC address * string Arbitrary label Response { \u201cuuid\u201d: \u201c\u201d, \u201cmac\u201d: \u201c52:54:00:a1:9c:ae\u201d, \u201cosInstalled\u201d: true, \u201crawQuery\u201d: \u201cmac=52:54:00:a1:9c:ae&os=installed\u201d } Metadata \u00b6 Finds the matching machine group and renders the group metadata, selectors, and query params in an \"env file\" style response. GET http://matchbox.foo/metadata?mac=52-54-00-a1-9c-ae&foo=bar&count=3&gate=true Query Parameters Name Type Description uuid string Hardware UUID mac string MAC address * string Arbitrary label Response META=data ETCD_NAME=node1 SOME_NESTED_DATA=some-value MAC=52:54:00:a1:9c:ae REQUEST_QUERY_MAC=52:54:00:a1:9c:ae REQUEST_QUERY_FOO=bar REQUEST_QUERY_COUNT=3 REQUEST_QUERY_GATE=true REQUEST_RAW_QUERY=mac=52-54-00-a1-9c-ae&foo=bar&count=3&gate=true OpenPGP signatures \u00b6 OpenPGP signature endpoints serve detached binary and ASCII armored signatures of rendered configs, if enabled. See OpenPGP Signing . Endpoint Signature Endpoint ASCII Signature Endpoint iPXE http://matchbox.foo/ipxe.sig http://matchbox.foo/ipxe.asc GRUB2 http://bootcf.foo/grub.sig http://matchbox.foo/grub.asc Ignition http://matchbox.foo/ignition.sig http://matchbox.foo/ignition.asc Cloud-Config http://matchbox.foo/cloud.sig http://matchbox.foo/cloud.asc Generic http://matchbox.foo/generic.sig http://matchbox.foo/generic.asc Metadata http://matchbox.foo/metadata.sig http://matchbox.foo/metadata.asc Get a config and its detached ASCII armored signature. GET http://matchbox.foo/ipxe?label=value GET http://matchbox.foo/ipxe.asc?label=value Response -----BEGIN PGP SIGNATURE----- wsBcBAEBCAAQBQJWoDHyCRCzUpbPLRRcKAAAqQ8IAGD+eC9kzc/U7h9tgwvvWwm9 suTmVSGlzC5RwTRXg6CKuW31m3WAin2b5zWRPa7MxxanYMhhBbOfrqg/4xi1tfdE w7ipmmgftl3re0np75Jt9K1rwGXUHTCs3yooz/zvqSvNSobG13FL5tp+Jl7a22wE +W7x9BukTytVgNLt3IDIxsJ/rAEYUm4zySftooDbFVKj/SK5w8xg4zLmE6Jxz6wp eaMlL1TEXy3NaFR0+hgbqM/tgeV2j6pmho8yaPF63iPnksH+gdmPiwasCfpSaJyr NO+p24BL3PHZyKw0nsrm275C913OxEVgnNZX7TQltaweW23Cd1YBNjcfb3zv+Zo= =mqZK -----END PGP SIGNATURE----- Assets \u00b6 If you need to serve static assets (e.g. kernel, initrd), matchbox can serve arbitrary assets from the -assets-path . matchbox.foo/assets/ \u2514\u2500\u2500 coreos \u2514\u2500\u2500 1967.3.0 \u251c\u2500\u2500 coreos_production_pxe.vmlinuz \u2514\u2500\u2500 coreos_production_pxe_image.cpio.gz \u2514\u2500\u2500 1153.0.0 \u251c\u2500\u2500 coreos_production_pxe.vmlinuz \u2514\u2500\u2500 coreos_production_pxe_image.cpio.gz","title":"HTTP API"},{"location":"api-http/#http-api","text":"","title":"HTTP API"},{"location":"api-http/#ipxe-script","text":"Serves a static iPXE boot script which gathers client machine attributes and chainloads to the iPXE endpoint. Use DHCP/TFTP to point iPXE clients to this endpoint as the next-server. GET http://matchbox.foo/boot.ipxe GET http://matchbox.foo/boot.ipxe.0 // for dnsmasq Response #!ipxe chain ipxe?uuid=${uuid}&mac=${mac:hexhyp}&domain=${domain}&hostname=${hostname}&serial=${serial} Client's booted with the /ipxe.boot endpoint will introspect and make a request to /ipxe with the uuid , mac , hostname , and serial value as query arguments.","title":"iPXE script"},{"location":"api-http/#ipxe","text":"Finds the profile for the machine and renders the network boot config (kernel, options, initrd) as an iPXE script. GET http://matchbox.foo/ipxe?label=value Query parameters Name Type Description uuid string Hardware UUID mac string MAC address * string Arbitrary label Response #!ipxe kernel /assets/coreos/1967.3.0/coreos_production_pxe.vmlinuz coreos.config.url=http://matchbox.foo:8080/ignition?uuid=${uuid}&mac=${mac:hexhyp} coreos.first_boot=1 coreos.autologin initrd /assets/coreos/1967.3.0/coreos_production_pxe_image.cpio.gz boot","title":"iPXE"},{"location":"api-http/#grub2","text":"Finds the profile for the machine and renders the network boot config as a GRUB config. Use DHCP/TFTP to point GRUB clients to this endpoint as the next-server. GET http://matchbox.foo/grub?label=value Query parameters Name Type Description uuid string Hardware UUID mac string MAC address * string Arbitrary label Response default=0 timeout=1 menuentry \"CoreOS\" { echo \"Loading kernel\" linuxefi \"(http;matchbox.foo:8080)/assets/coreos/1967.3.0/coreos_production_pxe.vmlinuz\" \"coreos.autologin\" \"coreos.config.url=http://matchbox.foo:8080/ignition\" \"coreos.first_boot\" echo \"Loading initrd\" initrdefi \"(http;matchbox.foo:8080)/assets/coreos/1967.3.0/coreos_production_pxe_image.cpio.gz\" }","title":"GRUB2"},{"location":"api-http/#cloud-config","text":"DEPRECATED: Finds the profile matching the machine and renders the corresponding Cloud-Config with group metadata, selectors, and query params. GET http://matchbox.foo/cloud?label=value Query Parameters Name Type Description uuid string Hardware UUID mac string MAC address * string Arbitrary label Response #cloud-config coreos : units : - name : etcd2.service command : start - name : fleet.service command : start","title":"Cloud config"},{"location":"api-http/#container-linux-config-ignition-config","text":"Finds the profile matching the machine and renders the corresponding Ignition Config with group metadata, selectors, and query params. GET http://matchbox.foo/ignition?label=value Query parameters Name Type Description uuid string Hardware UUID mac string MAC address * string Arbitrary label Response { \"ignition\" : { \"version\" : \"2.0.0\" }, \"systemd\" : { \"units\" : [{ \"name\" : \"example.service\" , \"enable\" : true , \"contents\" : \"[Service]\\nType=oneshot\\nExecStart=/usr/bin/echo Hello World\\n\\n[Install]\\nWantedBy=multi-user.target\" }] } }","title":"Container Linux Config / Ignition Config"},{"location":"api-http/#generic-config","text":"Finds the profile matching the machine and renders the corresponding generic config with group metadata, selectors, and query params. GET http://matchbox.foo/generic?label=value Query parameters Name Type Description uuid string Hardware UUID mac string MAC address * string Arbitrary label Response { \u201cuuid\u201d: \u201c\u201d, \u201cmac\u201d: \u201c52:54:00:a1:9c:ae\u201d, \u201cosInstalled\u201d: true, \u201crawQuery\u201d: \u201cmac=52:54:00:a1:9c:ae&os=installed\u201d }","title":"Generic config"},{"location":"api-http/#metadata","text":"Finds the matching machine group and renders the group metadata, selectors, and query params in an \"env file\" style response. GET http://matchbox.foo/metadata?mac=52-54-00-a1-9c-ae&foo=bar&count=3&gate=true Query Parameters Name Type Description uuid string Hardware UUID mac string MAC address * string Arbitrary label Response META=data ETCD_NAME=node1 SOME_NESTED_DATA=some-value MAC=52:54:00:a1:9c:ae REQUEST_QUERY_MAC=52:54:00:a1:9c:ae REQUEST_QUERY_FOO=bar REQUEST_QUERY_COUNT=3 REQUEST_QUERY_GATE=true REQUEST_RAW_QUERY=mac=52-54-00-a1-9c-ae&foo=bar&count=3&gate=true","title":"Metadata"},{"location":"api-http/#openpgp-signatures","text":"OpenPGP signature endpoints serve detached binary and ASCII armored signatures of rendered configs, if enabled. See OpenPGP Signing . Endpoint Signature Endpoint ASCII Signature Endpoint iPXE http://matchbox.foo/ipxe.sig http://matchbox.foo/ipxe.asc GRUB2 http://bootcf.foo/grub.sig http://matchbox.foo/grub.asc Ignition http://matchbox.foo/ignition.sig http://matchbox.foo/ignition.asc Cloud-Config http://matchbox.foo/cloud.sig http://matchbox.foo/cloud.asc Generic http://matchbox.foo/generic.sig http://matchbox.foo/generic.asc Metadata http://matchbox.foo/metadata.sig http://matchbox.foo/metadata.asc Get a config and its detached ASCII armored signature. GET http://matchbox.foo/ipxe?label=value GET http://matchbox.foo/ipxe.asc?label=value Response -----BEGIN PGP SIGNATURE----- wsBcBAEBCAAQBQJWoDHyCRCzUpbPLRRcKAAAqQ8IAGD+eC9kzc/U7h9tgwvvWwm9 suTmVSGlzC5RwTRXg6CKuW31m3WAin2b5zWRPa7MxxanYMhhBbOfrqg/4xi1tfdE w7ipmmgftl3re0np75Jt9K1rwGXUHTCs3yooz/zvqSvNSobG13FL5tp+Jl7a22wE +W7x9BukTytVgNLt3IDIxsJ/rAEYUm4zySftooDbFVKj/SK5w8xg4zLmE6Jxz6wp eaMlL1TEXy3NaFR0+hgbqM/tgeV2j6pmho8yaPF63iPnksH+gdmPiwasCfpSaJyr NO+p24BL3PHZyKw0nsrm275C913OxEVgnNZX7TQltaweW23Cd1YBNjcfb3zv+Zo= =mqZK -----END PGP SIGNATURE-----","title":"OpenPGP signatures"},{"location":"api-http/#assets","text":"If you need to serve static assets (e.g. kernel, initrd), matchbox can serve arbitrary assets from the -assets-path . matchbox.foo/assets/ \u2514\u2500\u2500 coreos \u2514\u2500\u2500 1967.3.0 \u251c\u2500\u2500 coreos_production_pxe.vmlinuz \u2514\u2500\u2500 coreos_production_pxe_image.cpio.gz \u2514\u2500\u2500 1153.0.0 \u251c\u2500\u2500 coreos_production_pxe.vmlinuz \u2514\u2500\u2500 coreos_production_pxe_image.cpio.gz","title":"Assets"},{"location":"cloud-config/","text":"Cloud Config \u00b6 Warning Migrate to Container Linux Configs . Cloud-Config support will be removed in the future. CoreOS Cloud-Config is a system for configuring machines with a Cloud-Config file or executable script from user-data. Cloud-Config runs in userspace on each boot and implements a subset of the cloud-init spec . See the cloud-config docs for details. Cloud-Config template files can be added in /var/lib/matchbox/cloud or in a cloud subdirectory of a custom -data-path . Template files may contain Go template elements which will be evaluated with group metadata, selectors, and query params. /var/lib/matchbox \u251c\u2500\u2500 cloud \u2502 \u251c\u2500\u2500 cloud.yaml \u2502 \u2514\u2500\u2500 script.sh \u251c\u2500\u2500 ignition \u2514\u2500\u2500 profiles Reference \u00b6 Reference a Cloud-Config in a Profile with cloud_id . When PXE booting, use the kernel option cloud-config-url to point to matchbox cloud-config endpoint . Examples \u00b6 Here is an example Cloud-Config which starts some units and writes a file. #cloud-config coreos : units : - name : etcd2.service command : start - name : fleet.service command : start write_files : - path : \"/home/core/welcome\" owner : \"core\" permissions : \"0644\" content : | {{.greeting}} The Cloud-Config Validator is also useful for checking your Cloud-Config files for errors. Comparison with Ignition \u00b6 Cloud-Config starts after userspace has started, on every boot. Ignition starts before PID 1 and only runs on the first boot. Ignition favors immutable infrastructure. Ignition is favored as the replacement for CoreOS Cloud-Config. Tasks often only need to be run once and can be performed more easily before systemd has started (e.g. configuring networking). Ignition can write service units for tasks that need to be run on each boot. Instead of depending on Cloud-Config variable substitution, Ignition favors using systemd's EnvironmentFile expansion to start units with a metadata file from a metadata source.","title":"Cloud-Config"},{"location":"cloud-config/#cloud-config","text":"Warning Migrate to Container Linux Configs . Cloud-Config support will be removed in the future. CoreOS Cloud-Config is a system for configuring machines with a Cloud-Config file or executable script from user-data. Cloud-Config runs in userspace on each boot and implements a subset of the cloud-init spec . See the cloud-config docs for details. Cloud-Config template files can be added in /var/lib/matchbox/cloud or in a cloud subdirectory of a custom -data-path . Template files may contain Go template elements which will be evaluated with group metadata, selectors, and query params. /var/lib/matchbox \u251c\u2500\u2500 cloud \u2502 \u251c\u2500\u2500 cloud.yaml \u2502 \u2514\u2500\u2500 script.sh \u251c\u2500\u2500 ignition \u2514\u2500\u2500 profiles","title":"Cloud Config"},{"location":"cloud-config/#reference","text":"Reference a Cloud-Config in a Profile with cloud_id . When PXE booting, use the kernel option cloud-config-url to point to matchbox cloud-config endpoint .","title":"Reference"},{"location":"cloud-config/#examples","text":"Here is an example Cloud-Config which starts some units and writes a file. #cloud-config coreos : units : - name : etcd2.service command : start - name : fleet.service command : start write_files : - path : \"/home/core/welcome\" owner : \"core\" permissions : \"0644\" content : | {{.greeting}} The Cloud-Config Validator is also useful for checking your Cloud-Config files for errors.","title":"Examples"},{"location":"cloud-config/#comparison-with-ignition","text":"Cloud-Config starts after userspace has started, on every boot. Ignition starts before PID 1 and only runs on the first boot. Ignition favors immutable infrastructure. Ignition is favored as the replacement for CoreOS Cloud-Config. Tasks often only need to be run once and can be performed more easily before systemd has started (e.g. configuring networking). Ignition can write service units for tasks that need to be run on each boot. Instead of depending on Cloud-Config variable substitution, Ignition favors using systemd's EnvironmentFile expansion to start units with a metadata file from a metadata source.","title":"Comparison with Ignition"},{"location":"config/","text":"Flags and variables \u00b6 Configuration arguments can be provided as flags or as environment variables. flag variable default example -address MATCHBOX_ADDRESS 127.0.0.1:8080 0.0.0.0:8080 -log-level MATCHBOX_LOG_LEVEL info critical, error, warning, notice, info, debug -data-path MATCHBOX_DATA_PATH /var/lib/matchbox ./examples -assets-path MATCHBOX_ASSETS_PATH /var/lib/matchbox/assets ./examples/assets -rpc-address MATCHBOX_RPC_ADDRESS (gRPC API disabled) 0.0.0.0:8081 -cert-file MATCHBOX_CERT_FILE /etc/matchbox/server.crt ./examples/etc/matchbox/server.crt -key-file MATCHBOX_KEY_FILE /etc/matchbox/server.key ./examples/etc/matchbox/server.key -ca-file MATCHBOX_CA_FILE /etc/matchbox/ca.crt ./examples/etc/matchbox/ca.crt -key-ring-path MATCHBOX_KEY_RING_PATH (no key ring) ~/.secrets/vault/matchbox/secring.gpg (no flag) MATCHBOX_PASSPHRASE (no passphrase) \"secret passphrase\" Files and directories \u00b6 Data Default Location data /var/lib/matchbox/{profiles,groups,ignition,cloud,generic} assets /var/lib/matchbox/assets gRPC API TLS Credentials Default Location CA certificate /etc/matchbox/ca.crt Server certificate /etc/matchbox/server.crt Server private key /etc/matchbox/server.key Client certificate /etc/matchbox/client.crt Client private key /etc/matchbox/client.key Version \u00b6 $ ./bin/matchbox -version $ sudo docker run quay.io/poseidon/matchbox:latest -version Usage \u00b6 Run the binary. $ ./bin/matchbox -address = 0 .0.0.0:8080 -log-level = debug -data-path = examples -assets-path = examples/assets Run the latest Docker image. $ sudo docker run -p 8080 :8080 --rm -v $PWD /examples/assets:/var/lib/matchbox/assets:Z quay.io/poseidon/matchbox:latest -address = 0 .0.0.0:8080 -log-level = debug With examples \u00b6 Mount examples to pre-load the example machine groups and profiles. Run the container. $ sudo docker run -p 8080 :8080 --rm -v $PWD /examples:/var/lib/matchbox:Z -v $PWD /examples/groups/etcd:/var/lib/matchbox/groups:Z quay.io/poseidon/matchbox:latest -address = 0 .0.0.0:8080 -log-level = debug With gRPC API \u00b6 The gRPC API allows clients with a TLS client certificate and key to make RPC requests to programmatically create or update matchbox resources. The API can be enabled with the -rpc-address flag and by providing a TLS server certificate and key with -cert-file and -key-file and a CA certificate for authenticating clients with -ca-file . Run the binary with TLS credentials from examples/etc/matchbox . $ ./bin/matchbox -address = 0 .0.0.0:8080 -rpc-address = 0 .0.0.0:8081 -log-level = debug -data-path = examples -assets-path = examples/assets -cert-file examples/etc/matchbox/server.crt -key-file examples/etc/matchbox/server.key -ca-file examples/etc/matchbox/ca.crt Clients, such as bootcmd , verify the server's certificate with a CA bundle passed via -ca-file and present a client certificate and key via -cert-file and -key-file to cal the gRPC API. $ ./bin/bootcmd profile list --endpoints 127 .0.0.1:8081 --ca-file examples/etc/matchbox/ca.crt --cert-file examples/etc/matchbox/client.crt --key-file examples/etc/matchbox/client.key With docker \u00b6 Run the Docker image with TLS credentials from examples/etc/matchbox . $ sudo docker run -p 8080 :8080 -p 8081 :8081 --rm -v $PWD /examples:/var/lib/matchbox:Z -v $PWD /examples/etc/matchbox:/etc/matchbox:Z,ro -v $PWD /examples/groups/etcd:/var/lib/matchbox/groups:Z quay.io/poseidon/matchbox:latest -address = 0 .0.0.0:8080 -rpc-address = 0 .0.0.0:8081 -log-level = debug A bootcmd client can call the gRPC API running at the IP used in the Docker example. $ ./bin/bootcmd profile list --endpoints 127 .0.0.1:8081 --ca-file examples/etc/matchbox/ca.crt --cert-file examples/etc/matchbox/client.crt --key-file examples/etc/matchbox/client.key With openPGP Signing \u00b6 Run with the binary with a test key. $ export MATCHBOX_PASSPHRASE = test $ ./bin/matchbox -address = 0 .0.0.0:8080 -key-ring-path matchbox/sign/fixtures/secring.gpg -data-path = examples -assets-path = examples/assets Run the container image with a test key. $ sudo docker run -p 8080 :8080 --rm --env MATCHBOX_PASSPHRASE = test -v $PWD /examples:/var/lib/matchbox:Z -v $PWD /examples/groups/etcd:/var/lib/matchbox/groups:Z -v $PWD /matchbox/sign/fixtures:/secrets:Z quay.io/poseidon/matchbox:latest -address = 0 .0.0.0:8080 -log-level = debug -key-ring-path secrets/secring.gpg","title":"Configuration"},{"location":"config/#flags-and-variables","text":"Configuration arguments can be provided as flags or as environment variables. flag variable default example -address MATCHBOX_ADDRESS 127.0.0.1:8080 0.0.0.0:8080 -log-level MATCHBOX_LOG_LEVEL info critical, error, warning, notice, info, debug -data-path MATCHBOX_DATA_PATH /var/lib/matchbox ./examples -assets-path MATCHBOX_ASSETS_PATH /var/lib/matchbox/assets ./examples/assets -rpc-address MATCHBOX_RPC_ADDRESS (gRPC API disabled) 0.0.0.0:8081 -cert-file MATCHBOX_CERT_FILE /etc/matchbox/server.crt ./examples/etc/matchbox/server.crt -key-file MATCHBOX_KEY_FILE /etc/matchbox/server.key ./examples/etc/matchbox/server.key -ca-file MATCHBOX_CA_FILE /etc/matchbox/ca.crt ./examples/etc/matchbox/ca.crt -key-ring-path MATCHBOX_KEY_RING_PATH (no key ring) ~/.secrets/vault/matchbox/secring.gpg (no flag) MATCHBOX_PASSPHRASE (no passphrase) \"secret passphrase\"","title":"Flags and variables"},{"location":"config/#files-and-directories","text":"Data Default Location data /var/lib/matchbox/{profiles,groups,ignition,cloud,generic} assets /var/lib/matchbox/assets gRPC API TLS Credentials Default Location CA certificate /etc/matchbox/ca.crt Server certificate /etc/matchbox/server.crt Server private key /etc/matchbox/server.key Client certificate /etc/matchbox/client.crt Client private key /etc/matchbox/client.key","title":"Files and directories"},{"location":"config/#version","text":"$ ./bin/matchbox -version $ sudo docker run quay.io/poseidon/matchbox:latest -version","title":"Version"},{"location":"config/#usage","text":"Run the binary. $ ./bin/matchbox -address = 0 .0.0.0:8080 -log-level = debug -data-path = examples -assets-path = examples/assets Run the latest Docker image. $ sudo docker run -p 8080 :8080 --rm -v $PWD /examples/assets:/var/lib/matchbox/assets:Z quay.io/poseidon/matchbox:latest -address = 0 .0.0.0:8080 -log-level = debug","title":"Usage"},{"location":"config/#with-examples","text":"Mount examples to pre-load the example machine groups and profiles. Run the container. $ sudo docker run -p 8080 :8080 --rm -v $PWD /examples:/var/lib/matchbox:Z -v $PWD /examples/groups/etcd:/var/lib/matchbox/groups:Z quay.io/poseidon/matchbox:latest -address = 0 .0.0.0:8080 -log-level = debug","title":"With examples"},{"location":"config/#with-grpc-api","text":"The gRPC API allows clients with a TLS client certificate and key to make RPC requests to programmatically create or update matchbox resources. The API can be enabled with the -rpc-address flag and by providing a TLS server certificate and key with -cert-file and -key-file and a CA certificate for authenticating clients with -ca-file . Run the binary with TLS credentials from examples/etc/matchbox . $ ./bin/matchbox -address = 0 .0.0.0:8080 -rpc-address = 0 .0.0.0:8081 -log-level = debug -data-path = examples -assets-path = examples/assets -cert-file examples/etc/matchbox/server.crt -key-file examples/etc/matchbox/server.key -ca-file examples/etc/matchbox/ca.crt Clients, such as bootcmd , verify the server's certificate with a CA bundle passed via -ca-file and present a client certificate and key via -cert-file and -key-file to cal the gRPC API. $ ./bin/bootcmd profile list --endpoints 127 .0.0.1:8081 --ca-file examples/etc/matchbox/ca.crt --cert-file examples/etc/matchbox/client.crt --key-file examples/etc/matchbox/client.key","title":"With gRPC API"},{"location":"config/#with-docker","text":"Run the Docker image with TLS credentials from examples/etc/matchbox . $ sudo docker run -p 8080 :8080 -p 8081 :8081 --rm -v $PWD /examples:/var/lib/matchbox:Z -v $PWD /examples/etc/matchbox:/etc/matchbox:Z,ro -v $PWD /examples/groups/etcd:/var/lib/matchbox/groups:Z quay.io/poseidon/matchbox:latest -address = 0 .0.0.0:8080 -rpc-address = 0 .0.0.0:8081 -log-level = debug A bootcmd client can call the gRPC API running at the IP used in the Docker example. $ ./bin/bootcmd profile list --endpoints 127 .0.0.1:8081 --ca-file examples/etc/matchbox/ca.crt --cert-file examples/etc/matchbox/client.crt --key-file examples/etc/matchbox/client.key","title":"With docker"},{"location":"config/#with-openpgp-signing","text":"Run with the binary with a test key. $ export MATCHBOX_PASSPHRASE = test $ ./bin/matchbox -address = 0 .0.0.0:8080 -key-ring-path matchbox/sign/fixtures/secring.gpg -data-path = examples -assets-path = examples/assets Run the container image with a test key. $ sudo docker run -p 8080 :8080 --rm --env MATCHBOX_PASSPHRASE = test -v $PWD /examples:/var/lib/matchbox:Z -v $PWD /examples/groups/etcd:/var/lib/matchbox/groups:Z -v $PWD /matchbox/sign/fixtures:/secrets:Z quay.io/poseidon/matchbox:latest -address = 0 .0.0.0:8080 -log-level = debug -key-ring-path secrets/secring.gpg","title":"With openPGP Signing"},{"location":"container-linux-config/","text":"Container Linux Configs \u00b6 A Container Linux Config is a YAML document which declares how Container Linux instances' disks should be provisioned on network boot and first-boot from disk. Configs can declare disk partitions, write files (regular files, systemd units, networkd units, etc.), and configure users. See the Container Linux Config spec . Ignition \u00b6 Container Linux Configs are validated and converted to machine-friendly Ignition configs (JSON) by matchbox when serving to booting machines. Ignition , the provisioning utility shipped in Container Linux, will parse and execute the Ignition config to realize the desired configuration. Matchbox users usually only need to write Container Linux Configs. Note: Container Linux directory names are still named \"ignition\" for historical reasons as outlined below. A future breaking change will rename to \"container-linux-config\". Adding Container Linux Configs \u00b6 Container Linux Config templates can be added to the /var/lib/matchbox/ignition directory or in an ignition subdirectory of a custom -data-path . Template files may contain Go template elements which will be evaluated with group metadata, selectors, and query params. /var/lib/matchbox \u251c\u2500\u2500 cloud \u251c\u2500\u2500 ignition \u2502 \u2514\u2500\u2500 k8s-controller.yaml \u2502 \u2514\u2500\u2500 etcd.yaml \u2502 \u2514\u2500\u2500 k8s-worker.yaml \u2502 \u2514\u2500\u2500 raw.ign \u2514\u2500\u2500 profiles Referencing in Profiles \u00b6 Profiles can include a Container Linux Config for provisioning machines. Specify the Container Linux Config in a Profile with ignition_id . When PXE booting, use the kernel option coreos.first_boot=1 and coreos.config.url to point to the matchbox Ignition endpoint . Examples \u00b6 Here is an example Container Linux Config template. Variables will be interpreted using group metadata, selectors, and query params. Matchbox will convert the config to Ignition to serve Container Linux machines. ignition/format-disk.yaml.tmpl: --- storage : disks : - device : /dev/sda wipe_table : true partitions : - label : ROOT filesystems : - name : root mount : device : \"/dev/sda1\" format : \"ext4\" create : force : true options : - \"-LROOT\" files : - filesystem : root path : /home/core/foo mode : 0644 user : id : 500 group : id : 500 contents : inline : | {{.example_contents}} {{ if index . \"ssh_authorized_keys\" }} passwd : users : - name : core ssh_authorized_keys : {{ range $element : = .ssh_authorized_keys }} - {{ $element }} {{ end }} {{ end }} The Ignition config response (formatted) to a query /ignition?label=value for a Container Linux instance supporting Ignition 2.0.0 would be: { \"ignition\" : { \"version\" : \"2.0.0\" , \"config\" : {} }, \"storage\" : { \"disks\" : [ { \"device\" : \"/dev/sda\" , \"wipeTable\" : true , \"partitions\" : [ { \"label\" : \"ROOT\" , \"number\" : 0 , \"size\" : 0 , \"start\" : 0 } ] } ], \"filesystems\" : [ { \"name\" : \"root\" , \"mount\" : { \"device\" : \"/dev/sda1\" , \"format\" : \"ext4\" , \"create\" : { \"force\" : true , \"options\" : [ \"-LROOT\" ] } } } ], \"files\" : [ { \"filesystem\" : \"root\" , \"path\" : \"/home/core/foo\" , \"contents\" : { \"source\" : \"data:,Example%20file%20contents%0A\" , \"verification\" : {} }, \"mode\" : 420 , \"user\" : { \"id\" : 500 }, \"group\" : { \"id\" : 500 } } ] }, \"systemd\" : {}, \"networkd\" : {}, \"passwd\" : {} } See examples/ignition for numerous Container Linux Config template examples. Raw Ignition \u00b6 If you prefer to design your own templating solution, raw Ignition files (suffixed with .ign or .ignition ) are served directly.","title":"Container Linux Config"},{"location":"container-linux-config/#container-linux-configs","text":"A Container Linux Config is a YAML document which declares how Container Linux instances' disks should be provisioned on network boot and first-boot from disk. Configs can declare disk partitions, write files (regular files, systemd units, networkd units, etc.), and configure users. See the Container Linux Config spec .","title":"Container Linux Configs"},{"location":"container-linux-config/#ignition","text":"Container Linux Configs are validated and converted to machine-friendly Ignition configs (JSON) by matchbox when serving to booting machines. Ignition , the provisioning utility shipped in Container Linux, will parse and execute the Ignition config to realize the desired configuration. Matchbox users usually only need to write Container Linux Configs. Note: Container Linux directory names are still named \"ignition\" for historical reasons as outlined below. A future breaking change will rename to \"container-linux-config\".","title":"Ignition"},{"location":"container-linux-config/#adding-container-linux-configs","text":"Container Linux Config templates can be added to the /var/lib/matchbox/ignition directory or in an ignition subdirectory of a custom -data-path . Template files may contain Go template elements which will be evaluated with group metadata, selectors, and query params. /var/lib/matchbox \u251c\u2500\u2500 cloud \u251c\u2500\u2500 ignition \u2502 \u2514\u2500\u2500 k8s-controller.yaml \u2502 \u2514\u2500\u2500 etcd.yaml \u2502 \u2514\u2500\u2500 k8s-worker.yaml \u2502 \u2514\u2500\u2500 raw.ign \u2514\u2500\u2500 profiles","title":"Adding Container Linux Configs"},{"location":"container-linux-config/#referencing-in-profiles","text":"Profiles can include a Container Linux Config for provisioning machines. Specify the Container Linux Config in a Profile with ignition_id . When PXE booting, use the kernel option coreos.first_boot=1 and coreos.config.url to point to the matchbox Ignition endpoint .","title":"Referencing in Profiles"},{"location":"container-linux-config/#examples","text":"Here is an example Container Linux Config template. Variables will be interpreted using group metadata, selectors, and query params. Matchbox will convert the config to Ignition to serve Container Linux machines. ignition/format-disk.yaml.tmpl: --- storage : disks : - device : /dev/sda wipe_table : true partitions : - label : ROOT filesystems : - name : root mount : device : \"/dev/sda1\" format : \"ext4\" create : force : true options : - \"-LROOT\" files : - filesystem : root path : /home/core/foo mode : 0644 user : id : 500 group : id : 500 contents : inline : | {{.example_contents}} {{ if index . \"ssh_authorized_keys\" }} passwd : users : - name : core ssh_authorized_keys : {{ range $element : = .ssh_authorized_keys }} - {{ $element }} {{ end }} {{ end }} The Ignition config response (formatted) to a query /ignition?label=value for a Container Linux instance supporting Ignition 2.0.0 would be: { \"ignition\" : { \"version\" : \"2.0.0\" , \"config\" : {} }, \"storage\" : { \"disks\" : [ { \"device\" : \"/dev/sda\" , \"wipeTable\" : true , \"partitions\" : [ { \"label\" : \"ROOT\" , \"number\" : 0 , \"size\" : 0 , \"start\" : 0 } ] } ], \"filesystems\" : [ { \"name\" : \"root\" , \"mount\" : { \"device\" : \"/dev/sda1\" , \"format\" : \"ext4\" , \"create\" : { \"force\" : true , \"options\" : [ \"-LROOT\" ] } } } ], \"files\" : [ { \"filesystem\" : \"root\" , \"path\" : \"/home/core/foo\" , \"contents\" : { \"source\" : \"data:,Example%20file%20contents%0A\" , \"verification\" : {} }, \"mode\" : 420 , \"user\" : { \"id\" : 500 }, \"group\" : { \"id\" : 500 } } ] }, \"systemd\" : {}, \"networkd\" : {}, \"passwd\" : {} } See examples/ignition for numerous Container Linux Config template examples.","title":"Examples"},{"location":"container-linux-config/#raw-ignition","text":"If you prefer to design your own templating solution, raw Ignition files (suffixed with .ign or .ignition ) are served directly.","title":"Raw Ignition"},{"location":"deployment/","text":"Installation \u00b6 This guide walks through deploying the matchbox service on a Linux host (as a binary or container image) or on a Kubernetes cluster. Provisoner \u00b6 Matchbox is a service for network booting and provisioning machines to create Fedora CoreOS or Flatcar Linux clusters. Matchbox may installed on a host server or Kubernetes cluster that can serve configs to client machines in a lab or datacenter. Choose one of the supported installation options: Matchbox binary Container image Kubernetes manifests Download \u00b6 Download the latest Matchbox release . $ wget https://github.com/poseidon/matchbox/releases/download/v0.9.0/matchbox-v0.9.0-linux-amd64.tar.gz $ wget https://github.com/poseidon/matchbox/releases/download/v0.9.0/matchbox-v0.9.0-linux-amd64.tar.gz.asc Verify the release has been signed by Dalton Hubble's GPG Key 's signing subkey. $ gpg --keyserver keyserver.ubuntu.com --recv-key 2E3D92BF07D9DDCCB3BAE4A48F515AD1602065C8 $ gpg --verify matchbox-v0.9.0-linux-amd64.tar.gz.asc matchbox-v0.9.0-linux-amd64.tar.gz gpg: Good signature from \"Dalton Hubble <dghubble@gmail.com>\" Untar the release. $ tar xzvf matchbox-v0.9.0-linux-amd64.tar.gz $ cd matchbox-v0.9.0-linux-amd64 Install \u00b6 Run Matchbox as a binary, a container image, or on Kubernetes. Matchbox Binary \u00b6 Pre-built binaries are available for generic Linux distributions. Copy the matchbox static binary to an appropriate location on the host. $ sudo cp matchbox /usr/local/bin Set up User/Group \u00b6 The matchbox service should be run by a non-root user with access to the matchbox data directory ( /var/lib/matchbox ). Create a matchbox user and group. $ sudo useradd -U matchbox $ sudo mkdir -p /var/lib/matchbox/assets $ sudo chown -R matchbox:matchbox /var/lib/matchbox Create systemd service \u00b6 Copy the provided matchbox systemd unit file. $ sudo cp contrib/systemd/matchbox.service /etc/systemd/system/matchbox.service systemd dropins \u00b6 Customize Matchbox by editing the systemd unit or adding a systemd dropin. Find the complete set of matchbox flags and environment variables at config . $ sudo systemctl edit matchbox By default, the read-only HTTP machine endpoint will be exposed on port 8080 . # /etc/systemd/system/matchbox.service.d/override.conf [Service] Environment = \"MATCHBOX_ADDRESS=0.0.0.0:8080\" Environment = \"MATCHBOX_LOG_LEVEL=debug\" A common customization is enabling the gRPC API to allow clients with a TLS client certificate to change machine configs. # /etc/systemd/system/matchbox.service.d/override.conf [Service] Environment = \"MATCHBOX_ADDRESS=0.0.0.0:8080\" Environment = \"MATCHBOX_RPC_ADDRESS=0.0.0.0:8081\" Customize matchbox to suit your preferences. Start \u00b6 Start the Matchbox service and enable it if you'd like it to start on every boot. $ sudo systemctl daemon-reload $ sudo systemctl start matchbox $ sudo systemctl enable matchbox Container Image \u00b6 Run the container image with Podman, mkdir -p /var/lib/matchbox/assets podman run --net=host --rm -v /var/lib/matchbox:/var/lib/matchbox:Z -v /etc/matchbox:/etc/matchbox:Z,ro quay.io/poseidon/matchbox:v0.9.0 -address=0.0.0.0:8080 -rpc-address=0.0.0.0:8081 -log-level=debug Or with Docker, mkdir -p /var/lib/matchbox/assets sudo docker run --net=host --rm -v /var/lib/matchbox:/var/lib/matchbox:Z -v /etc/matchbox:/etc/matchbox:Z,ro quay.io/poseidon/matchbox:v0.9.0 -address=0.0.0.0:8080 -rpc-address=0.0.0.0:8081 -log-level=debug Create machine profiles, groups, or Ignition configs by adding files to /var/lib/matchbox . Kubernetes \u00b6 Install Matchbox on a Kubernetes cluster with the example manifests. $ kubectl apply -R -f contrib/k8s $ kubectl get services NAME CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE matchbox 10 .3.0.145 <none> 8080 /TCP,8081/TCP 46m Example manifests in contrib/k8s enable the gRPC API to allow client apps to update matchbox objects. Generate TLS server certificates for matchbox-rpc.example.com as shown and create a Kubernetes secret. Alternately, edit the example manifests if you don't need the gRPC API enabled. $ kubectl create secret generic matchbox-rpc --from-file = ca.crt --from-file = server.crt --from-file = server.key Create an Ingress resource to expose the HTTP read-only and gRPC API endpoints. The Ingress example requires the cluster to have a functioning Nginx Ingress Controller . $ kubectl create -f contrib/k8s/matchbox-ingress.yaml $ kubectl get ingress NAME HOSTS ADDRESS PORTS AGE matchbox matchbox.example.com 10 .128.0.3,10... 80 29m matchbox-rpc matchbox-rpc.example.com 10 .128.0.3,10... 80 , 443 29m Add DNS records matchbox.example.com and matchbox-rpc.example.com to route traffic to the Ingress Controller. Verify http://matchbox.example.com responds with the text \"matchbox\" and verify gRPC clients can connect to matchbox-rpc.example.com:443 . $ curl http://matchbox.example.com $ openssl s_client -connect matchbox-rpc.example.com:443 -CAfile ca.crt -cert client.crt -key client.key Firewall \u00b6 Allow your port choices on the provisioner's firewall so the clients can access the service. Here are the commands for those using firewalld : $ sudo firewall-cmd --zone = MYZONE --add-port = 8080 /tcp --permanent $ sudo firewall-cmd --zone = MYZONE --add-port = 8081 /tcp --permanent Generate TLS Certificates \u00b6 The Matchbox gRPC API allows clients (terraform-provider-matchbox) to create and update Matchbox resources. TLS credentials are needed for client authentication and to establish a secure communication channel. Client machines (those PXE booting) read from the HTTP endpoints and do not require this setup. The cert-gen helper script generates a self-signed CA, server certificate, and client certificate. Prefer your organization's PKI, if possible Navigate to the scripts/tls directory. $ cd scripts/tls Export SAN to set the Subject Alt Names which should be used in certificates. Provide the fully qualified domain name or IP (discouraged) where Matchbox will be installed. # DNS or IP Subject Alt Names where matchbox runs $ export SAN = DNS.1:matchbox.example.com,IP.1:172.17.0.2 Generate a ca.crt , server.crt , server.key , client.crt , and client.key . $ ./cert-gen Move TLS credentials to the matchbox server's default location. $ sudo mkdir -p /etc/matchbox $ sudo cp ca.crt server.crt server.key /etc/matchbox $ sudo chown -R matchbox:matchbox /etc/matchbox Save client.crt , client.key , and ca.crt for later use (e.g. ~/.matchbox ). $ mkdir -p ~/.matchbox $ cp client.crt client.key ca.crt ~/.matchbox/ Verify \u00b6 Verify the matchbox service is running and can be reached by client machines (those being provisioned). $ systemctl status matchbox # Matchbox binary method $ dig matchbox.example.com Verify you receive a response from the HTTP and API endpoints. $ curl http://matchbox.example.com:8080 matchbox If you enabled the gRPC API, $ openssl s_client -connect matchbox.example.com:8081 -CAfile scripts/tls/ca.crt -cert scripts/tls/client.crt -key scripts/tls/client.key CONNECTED ( 00000003 ) depth = 1 CN = fake-ca verify return :1 depth = 0 CN = fake-server verify return :1 --- Certificate chain 0 s:/CN = fake-server i:/CN = fake-ca --- .... Download Images (optional) \u00b6 Matchbox can serve OS images in development or lab environments to reduce bandwidth usage and increase the speed of PXE boots and installs to disk. Download a recent Fedora CoreOS or Flatcar Linux release. $ ./scripts/get-fedora-coreos stable 36.20220618.3.1 . $ ./scripts/get-flatcar stable 3227.2.0 . Move the images to /var/lib/matchbox/assets , /var/lib/matchbox/assets/fedora-coreos/ \u251c\u2500\u2500 fedora-coreos-36.20220618.3.1-live-initramfs.x86_64.img \u251c\u2500\u2500 fedora-coreos-36.20220618.3.1-live-kernel-x86_64 \u251c\u2500\u2500 fedora-coreos-36.20220618.3.1-live-rootfs.x86_64.img /var/lib/matchbox/assets/flatcar/ \u2514\u2500\u2500 3227.2.0 \u251c\u2500\u2500 Flatcar_Image_Signing_Key.asc \u251c\u2500\u2500 flatcar_production_image.bin.bz2 \u251c\u2500\u2500 flatcar_production_image.bin.bz2.sig \u251c\u2500\u2500 flatcar_production_pxe_image.cpio.gz \u251c\u2500\u2500 flatcar_production_pxe_image.cpio.gz.sig \u251c\u2500\u2500 flatcar_production_pxe.vmlinuz \u251c\u2500\u2500 flatcar_production_pxe.vmlinuz.sig \u2514\u2500\u2500 version.txt and verify the images are accessible. $ curl http://matchbox.example.com:8080/assets/fedora-coreos/ <pre>... For large production environments, use a cache proxy or mirror suitable for your environment to serve images. Network \u00b6 Review network setup with your network administrator to set up DHCP, TFTP, and DNS services on your network. At a high level, your goals are to: Chainload PXE firmwares to iPXE Point iPXE client machines to the matchbox iPXE HTTP endpoint http://matchbox.example.com:8080/boot.ipxe Ensure matchbox.example.com resolves to your matchbox deployment Poseidon provides dnsmasq as quay.io/poseidon/dnsmasq . TLS \u00b6 Matchbox can serve the read-only HTTP API with TLS. Name Type Description -web-ssl bool true/false -web-cert-file string Path to the server TLS certificate file -web-key-file string Path to the server TLS key file However, it is more common to use an Ingress Controller (Kubernetes) to terminate TLS. Operational notes \u00b6 Secrets: Matchbox can be run as a public facing service. However, you must follow best practices and avoid writing secret material into machine user-data. Instead, load secret materials from an internal secret store. Storage: Example manifests use Kubernetes emptyDir volumes to store matchbox data. Swap those out for a Kubernetes persistent volume if available.","title":"Deployment"},{"location":"deployment/#installation","text":"This guide walks through deploying the matchbox service on a Linux host (as a binary or container image) or on a Kubernetes cluster.","title":"Installation"},{"location":"deployment/#provisoner","text":"Matchbox is a service for network booting and provisioning machines to create Fedora CoreOS or Flatcar Linux clusters. Matchbox may installed on a host server or Kubernetes cluster that can serve configs to client machines in a lab or datacenter. Choose one of the supported installation options: Matchbox binary Container image Kubernetes manifests","title":"Provisoner"},{"location":"deployment/#download","text":"Download the latest Matchbox release . $ wget https://github.com/poseidon/matchbox/releases/download/v0.9.0/matchbox-v0.9.0-linux-amd64.tar.gz $ wget https://github.com/poseidon/matchbox/releases/download/v0.9.0/matchbox-v0.9.0-linux-amd64.tar.gz.asc Verify the release has been signed by Dalton Hubble's GPG Key 's signing subkey. $ gpg --keyserver keyserver.ubuntu.com --recv-key 2E3D92BF07D9DDCCB3BAE4A48F515AD1602065C8 $ gpg --verify matchbox-v0.9.0-linux-amd64.tar.gz.asc matchbox-v0.9.0-linux-amd64.tar.gz gpg: Good signature from \"Dalton Hubble <dghubble@gmail.com>\" Untar the release. $ tar xzvf matchbox-v0.9.0-linux-amd64.tar.gz $ cd matchbox-v0.9.0-linux-amd64","title":"Download"},{"location":"deployment/#install","text":"Run Matchbox as a binary, a container image, or on Kubernetes.","title":"Install"},{"location":"deployment/#matchbox-binary","text":"Pre-built binaries are available for generic Linux distributions. Copy the matchbox static binary to an appropriate location on the host. $ sudo cp matchbox /usr/local/bin","title":"Matchbox Binary"},{"location":"deployment/#set-up-usergroup","text":"The matchbox service should be run by a non-root user with access to the matchbox data directory ( /var/lib/matchbox ). Create a matchbox user and group. $ sudo useradd -U matchbox $ sudo mkdir -p /var/lib/matchbox/assets $ sudo chown -R matchbox:matchbox /var/lib/matchbox","title":"Set up User/Group"},{"location":"deployment/#create-systemd-service","text":"Copy the provided matchbox systemd unit file. $ sudo cp contrib/systemd/matchbox.service /etc/systemd/system/matchbox.service","title":"Create systemd service"},{"location":"deployment/#systemd-dropins","text":"Customize Matchbox by editing the systemd unit or adding a systemd dropin. Find the complete set of matchbox flags and environment variables at config . $ sudo systemctl edit matchbox By default, the read-only HTTP machine endpoint will be exposed on port 8080 . # /etc/systemd/system/matchbox.service.d/override.conf [Service] Environment = \"MATCHBOX_ADDRESS=0.0.0.0:8080\" Environment = \"MATCHBOX_LOG_LEVEL=debug\" A common customization is enabling the gRPC API to allow clients with a TLS client certificate to change machine configs. # /etc/systemd/system/matchbox.service.d/override.conf [Service] Environment = \"MATCHBOX_ADDRESS=0.0.0.0:8080\" Environment = \"MATCHBOX_RPC_ADDRESS=0.0.0.0:8081\" Customize matchbox to suit your preferences.","title":"systemd dropins"},{"location":"deployment/#start","text":"Start the Matchbox service and enable it if you'd like it to start on every boot. $ sudo systemctl daemon-reload $ sudo systemctl start matchbox $ sudo systemctl enable matchbox","title":"Start"},{"location":"deployment/#container-image","text":"Run the container image with Podman, mkdir -p /var/lib/matchbox/assets podman run --net=host --rm -v /var/lib/matchbox:/var/lib/matchbox:Z -v /etc/matchbox:/etc/matchbox:Z,ro quay.io/poseidon/matchbox:v0.9.0 -address=0.0.0.0:8080 -rpc-address=0.0.0.0:8081 -log-level=debug Or with Docker, mkdir -p /var/lib/matchbox/assets sudo docker run --net=host --rm -v /var/lib/matchbox:/var/lib/matchbox:Z -v /etc/matchbox:/etc/matchbox:Z,ro quay.io/poseidon/matchbox:v0.9.0 -address=0.0.0.0:8080 -rpc-address=0.0.0.0:8081 -log-level=debug Create machine profiles, groups, or Ignition configs by adding files to /var/lib/matchbox .","title":"Container Image"},{"location":"deployment/#kubernetes","text":"Install Matchbox on a Kubernetes cluster with the example manifests. $ kubectl apply -R -f contrib/k8s $ kubectl get services NAME CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE matchbox 10 .3.0.145 <none> 8080 /TCP,8081/TCP 46m Example manifests in contrib/k8s enable the gRPC API to allow client apps to update matchbox objects. Generate TLS server certificates for matchbox-rpc.example.com as shown and create a Kubernetes secret. Alternately, edit the example manifests if you don't need the gRPC API enabled. $ kubectl create secret generic matchbox-rpc --from-file = ca.crt --from-file = server.crt --from-file = server.key Create an Ingress resource to expose the HTTP read-only and gRPC API endpoints. The Ingress example requires the cluster to have a functioning Nginx Ingress Controller . $ kubectl create -f contrib/k8s/matchbox-ingress.yaml $ kubectl get ingress NAME HOSTS ADDRESS PORTS AGE matchbox matchbox.example.com 10 .128.0.3,10... 80 29m matchbox-rpc matchbox-rpc.example.com 10 .128.0.3,10... 80 , 443 29m Add DNS records matchbox.example.com and matchbox-rpc.example.com to route traffic to the Ingress Controller. Verify http://matchbox.example.com responds with the text \"matchbox\" and verify gRPC clients can connect to matchbox-rpc.example.com:443 . $ curl http://matchbox.example.com $ openssl s_client -connect matchbox-rpc.example.com:443 -CAfile ca.crt -cert client.crt -key client.key","title":"Kubernetes"},{"location":"deployment/#firewall","text":"Allow your port choices on the provisioner's firewall so the clients can access the service. Here are the commands for those using firewalld : $ sudo firewall-cmd --zone = MYZONE --add-port = 8080 /tcp --permanent $ sudo firewall-cmd --zone = MYZONE --add-port = 8081 /tcp --permanent","title":"Firewall"},{"location":"deployment/#generate-tls-certificates","text":"The Matchbox gRPC API allows clients (terraform-provider-matchbox) to create and update Matchbox resources. TLS credentials are needed for client authentication and to establish a secure communication channel. Client machines (those PXE booting) read from the HTTP endpoints and do not require this setup. The cert-gen helper script generates a self-signed CA, server certificate, and client certificate. Prefer your organization's PKI, if possible Navigate to the scripts/tls directory. $ cd scripts/tls Export SAN to set the Subject Alt Names which should be used in certificates. Provide the fully qualified domain name or IP (discouraged) where Matchbox will be installed. # DNS or IP Subject Alt Names where matchbox runs $ export SAN = DNS.1:matchbox.example.com,IP.1:172.17.0.2 Generate a ca.crt , server.crt , server.key , client.crt , and client.key . $ ./cert-gen Move TLS credentials to the matchbox server's default location. $ sudo mkdir -p /etc/matchbox $ sudo cp ca.crt server.crt server.key /etc/matchbox $ sudo chown -R matchbox:matchbox /etc/matchbox Save client.crt , client.key , and ca.crt for later use (e.g. ~/.matchbox ). $ mkdir -p ~/.matchbox $ cp client.crt client.key ca.crt ~/.matchbox/","title":"Generate TLS Certificates"},{"location":"deployment/#verify","text":"Verify the matchbox service is running and can be reached by client machines (those being provisioned). $ systemctl status matchbox # Matchbox binary method $ dig matchbox.example.com Verify you receive a response from the HTTP and API endpoints. $ curl http://matchbox.example.com:8080 matchbox If you enabled the gRPC API, $ openssl s_client -connect matchbox.example.com:8081 -CAfile scripts/tls/ca.crt -cert scripts/tls/client.crt -key scripts/tls/client.key CONNECTED ( 00000003 ) depth = 1 CN = fake-ca verify return :1 depth = 0 CN = fake-server verify return :1 --- Certificate chain 0 s:/CN = fake-server i:/CN = fake-ca --- ....","title":"Verify"},{"location":"deployment/#download-images-optional","text":"Matchbox can serve OS images in development or lab environments to reduce bandwidth usage and increase the speed of PXE boots and installs to disk. Download a recent Fedora CoreOS or Flatcar Linux release. $ ./scripts/get-fedora-coreos stable 36.20220618.3.1 . $ ./scripts/get-flatcar stable 3227.2.0 . Move the images to /var/lib/matchbox/assets , /var/lib/matchbox/assets/fedora-coreos/ \u251c\u2500\u2500 fedora-coreos-36.20220618.3.1-live-initramfs.x86_64.img \u251c\u2500\u2500 fedora-coreos-36.20220618.3.1-live-kernel-x86_64 \u251c\u2500\u2500 fedora-coreos-36.20220618.3.1-live-rootfs.x86_64.img /var/lib/matchbox/assets/flatcar/ \u2514\u2500\u2500 3227.2.0 \u251c\u2500\u2500 Flatcar_Image_Signing_Key.asc \u251c\u2500\u2500 flatcar_production_image.bin.bz2 \u251c\u2500\u2500 flatcar_production_image.bin.bz2.sig \u251c\u2500\u2500 flatcar_production_pxe_image.cpio.gz \u251c\u2500\u2500 flatcar_production_pxe_image.cpio.gz.sig \u251c\u2500\u2500 flatcar_production_pxe.vmlinuz \u251c\u2500\u2500 flatcar_production_pxe.vmlinuz.sig \u2514\u2500\u2500 version.txt and verify the images are accessible. $ curl http://matchbox.example.com:8080/assets/fedora-coreos/ <pre>... For large production environments, use a cache proxy or mirror suitable for your environment to serve images.","title":"Download Images (optional)"},{"location":"deployment/#network","text":"Review network setup with your network administrator to set up DHCP, TFTP, and DNS services on your network. At a high level, your goals are to: Chainload PXE firmwares to iPXE Point iPXE client machines to the matchbox iPXE HTTP endpoint http://matchbox.example.com:8080/boot.ipxe Ensure matchbox.example.com resolves to your matchbox deployment Poseidon provides dnsmasq as quay.io/poseidon/dnsmasq .","title":"Network"},{"location":"deployment/#tls","text":"Matchbox can serve the read-only HTTP API with TLS. Name Type Description -web-ssl bool true/false -web-cert-file string Path to the server TLS certificate file -web-key-file string Path to the server TLS key file However, it is more common to use an Ingress Controller (Kubernetes) to terminate TLS.","title":"TLS"},{"location":"deployment/#operational-notes","text":"Secrets: Matchbox can be run as a public facing service. However, you must follow best practices and avoid writing secret material into machine user-data. Instead, load secret materials from an internal secret store. Storage: Example manifests use Kubernetes emptyDir volumes to store matchbox data. Swap those out for a Kubernetes persistent volume if available.","title":"Operational notes"},{"location":"getting-started-docker/","text":"Getting started with Docker \u00b6 In this tutorial, we'll run matchbox on a Linux machine with Docker to network boot and provision local QEMU/KVM machines as Fedora CoreOS or Flatcar Linux machines. You'll be able to test network setups and Ignition provisioning. Note To provision physical machines, see network setup and deployment . Requirements \u00b6 Install the package dependencies and start the Docker daemon. $ # Fedora $ sudo dnf install docker virt-install virt-manager $ sudo systemctl start docker $ # Debian/Ubuntu $ # check Docker's docs to install Docker 1.8+ on Debian/Ubuntu $ sudo apt-get install virt-manager virtinst qemu-kvm Clone the matchbox source which contains the examples and scripts. $ git clone https://github.com/poseidon/matchbox.git $ cd matchbox Download Fedora CoreOS or Flatcar Linux image assets to examples/assets . $ ./scripts/get-fedora-coreos stable 36 .20220618.3.1 ./examples/assets $ ./scripts/get-flatcar stable 3227 .2.0 ./examples/assets For development convenience, add /etc/hosts entries for nodes so they may be referenced by name. # /etc/hosts ... 172 .17.0.21 node1.example.com 172 .17.0.22 node2.example.com 172 .17.0.23 node3.example.com Containers \u00b6 Run the matchbox and dnsmasq services on the docker0 bridge. dnsmasq will run DHCP, DNS and TFTP services to create a suitable network boot environment. matchbox will serve configs to machines as they PXE boot. The devnet convenience script can start these services and accepts the name of any example in examples . $ sudo ./scripts/devnet create fedora-coreos Inspect the logs. $ sudo ./scripts/devnet status Inspect the examples and Matchbox endpoints to see how machines (e.g. node1 with MAC 52:54:00:a1:9c:ae ) are mapped to Profiles, and therefore iPXE and Ignition configs. iPXE http://127.0.0.1:8080/ipxe?mac=52:54:00:a1:9c:ae Ignition http://127.0.0.1:8080/ignition?mac=52:54:00:a1:9c:ae Metadata http://127.0.0.1:8080/metadata?mac=52:54:00:a1:9c:ae Manual \u00b6 If you prefer to start the containers yourself, instead of using devnet , $ sudo docker run -p 8080 :8080 --rm -v $PWD /examples:/var/lib/matchbox:Z -v $PWD /examples/groups/fedora-coreos:/var/lib/matchbox/groups:Z quay.io/poseidon/matchbox:latest -address = 0 .0.0.0:8080 -log-level = debug $ sudo docker run --name dnsmasq --cap-add = NET_ADMIN -v $PWD /contrib/dnsmasq/docker0.conf:/etc/dnsmasq.conf:Z quay.io/poseidon/dnsmasq -d Client VMs \u00b6 Create QEMU/KVM VMs which have known hardware attributes. The nodes will be attached to the docker0 bridge, where Docker containers run. $ sudo ./scripts/libvirt create If you provisioned nodes with an SSH key, you can SSH after bring-up. $ ssh core@node1.example.com If you set a console=ttyS0 kernel arg, you can connect to the serial console of any node (ctrl+] to exit). $ sudo virsh console node1 You can also use virt-manager to watch the console. $ sudo virt-manager Use the wrapper script to act on all nodes. $ sudo ./scripts/libvirt [ start | reboot | shutdown | poweroff | destroy ] Verify \u00b6 The VMs should network boot and provision themselves as declared. cat /etc/os-release Clean up \u00b6 Clean up the containers and VM machines. $ sudo ./scripts/devnet destroy $ sudo ./scripts/libvirt destroy Going Further \u00b6 Learn more about matchbox or explore the other examples . Try different examples and Ignition declarations: Declare an SSH authorized public key (see examples README) Declare a systemd unit Declare file or directory content","title":"Getting started with Docker"},{"location":"getting-started-docker/#getting-started-with-docker","text":"In this tutorial, we'll run matchbox on a Linux machine with Docker to network boot and provision local QEMU/KVM machines as Fedora CoreOS or Flatcar Linux machines. You'll be able to test network setups and Ignition provisioning. Note To provision physical machines, see network setup and deployment .","title":"Getting started with Docker"},{"location":"getting-started-docker/#requirements","text":"Install the package dependencies and start the Docker daemon. $ # Fedora $ sudo dnf install docker virt-install virt-manager $ sudo systemctl start docker $ # Debian/Ubuntu $ # check Docker's docs to install Docker 1.8+ on Debian/Ubuntu $ sudo apt-get install virt-manager virtinst qemu-kvm Clone the matchbox source which contains the examples and scripts. $ git clone https://github.com/poseidon/matchbox.git $ cd matchbox Download Fedora CoreOS or Flatcar Linux image assets to examples/assets . $ ./scripts/get-fedora-coreos stable 36 .20220618.3.1 ./examples/assets $ ./scripts/get-flatcar stable 3227 .2.0 ./examples/assets For development convenience, add /etc/hosts entries for nodes so they may be referenced by name. # /etc/hosts ... 172 .17.0.21 node1.example.com 172 .17.0.22 node2.example.com 172 .17.0.23 node3.example.com","title":"Requirements"},{"location":"getting-started-docker/#containers","text":"Run the matchbox and dnsmasq services on the docker0 bridge. dnsmasq will run DHCP, DNS and TFTP services to create a suitable network boot environment. matchbox will serve configs to machines as they PXE boot. The devnet convenience script can start these services and accepts the name of any example in examples . $ sudo ./scripts/devnet create fedora-coreos Inspect the logs. $ sudo ./scripts/devnet status Inspect the examples and Matchbox endpoints to see how machines (e.g. node1 with MAC 52:54:00:a1:9c:ae ) are mapped to Profiles, and therefore iPXE and Ignition configs. iPXE http://127.0.0.1:8080/ipxe?mac=52:54:00:a1:9c:ae Ignition http://127.0.0.1:8080/ignition?mac=52:54:00:a1:9c:ae Metadata http://127.0.0.1:8080/metadata?mac=52:54:00:a1:9c:ae","title":"Containers"},{"location":"getting-started-docker/#manual","text":"If you prefer to start the containers yourself, instead of using devnet , $ sudo docker run -p 8080 :8080 --rm -v $PWD /examples:/var/lib/matchbox:Z -v $PWD /examples/groups/fedora-coreos:/var/lib/matchbox/groups:Z quay.io/poseidon/matchbox:latest -address = 0 .0.0.0:8080 -log-level = debug $ sudo docker run --name dnsmasq --cap-add = NET_ADMIN -v $PWD /contrib/dnsmasq/docker0.conf:/etc/dnsmasq.conf:Z quay.io/poseidon/dnsmasq -d","title":"Manual"},{"location":"getting-started-docker/#client-vms","text":"Create QEMU/KVM VMs which have known hardware attributes. The nodes will be attached to the docker0 bridge, where Docker containers run. $ sudo ./scripts/libvirt create If you provisioned nodes with an SSH key, you can SSH after bring-up. $ ssh core@node1.example.com If you set a console=ttyS0 kernel arg, you can connect to the serial console of any node (ctrl+] to exit). $ sudo virsh console node1 You can also use virt-manager to watch the console. $ sudo virt-manager Use the wrapper script to act on all nodes. $ sudo ./scripts/libvirt [ start | reboot | shutdown | poweroff | destroy ]","title":"Client VMs"},{"location":"getting-started-docker/#verify","text":"The VMs should network boot and provision themselves as declared. cat /etc/os-release","title":"Verify"},{"location":"getting-started-docker/#clean-up","text":"Clean up the containers and VM machines. $ sudo ./scripts/devnet destroy $ sudo ./scripts/libvirt destroy","title":"Clean up"},{"location":"getting-started-docker/#going-further","text":"Learn more about matchbox or explore the other examples . Try different examples and Ignition declarations: Declare an SSH authorized public key (see examples README) Declare a systemd unit Declare file or directory content","title":"Going Further"},{"location":"getting-started/","text":"Getting started \u00b6 In this tutorial, we'll use matchbox with Terraform to provision Fedora CoreOS or Flatcar Linux machines. We'll install the matchbox service, setup a PXE network boot environment, and use Terraform configs to declare infrastructure and apply resources on matchbox . matchbox \u00b6 Install matchbox on a host server or Kubernetes cluster. Generate TLS credentials and enable the gRPC API as directed. Save the ca.crt , client.crt , and client.key on your local machine (e.g. ~/.matchbox ). Installing on a Linux distro Installing on Kubernetes Running with docker Verify the matchbox read-only HTTP endpoints are accessible. $ curl http://matchbox.example.com:8080 matchbox Verify your TLS client certificate and key can be used to access the gRPC API. $ openssl s_client -connect matchbox.example.com:8081 \\ -CAfile ~/.matchbox/ca.crt \\ -cert ~/.matchbox/client.crt \\ -key ~/.matchbox/client.key Terraform \u00b6 Install Terraform v0.13+ on your system. $ terraform version Terraform v1.1.8 Examples \u00b6 Clone the matchbox source. $ git clone https://github.com/poseidon/matchbox.git $ cd matchbox/examples/terraform Select from the Terraform examples . For example, fedora-coreos-install - PXE boot, install Fedora CoreOS to disk, reboot, and machines come up with your SSH authorized key set flatcar-install - PXE boot, install Flatcar Linux to disk, reboot, and machines come up with your SSH authorized key set These aren't exactly full clusters, but they show declarations and network provisioning. $ cd fedora-coreos-install # or flatcar-install Note Fedora CoreOS images are only served via HTTPS, so your iPXE firmware must be compiled to support HTTPS downloads. Let's review the terraform config and learn a bit about Matchbox. Provider \u00b6 Matchbox is configured as a provider platform for bare-metal resources. // Configure the matchbox provider provider \"matchbox\" { endpoint = var.matchbox_rpc_endpoint client_cert = file ( \"~/.matchbox/client.crt\" ) client_key = file ( \"~/.matchbox/client.key\" ) ca = file ( \"~/.matchbox/ca.crt\" ) } terraform { required_providers { ct = { source = \"poseidon/ct\" version = \"0.10.0\" } matchbox = { source = \"poseidon/matchbox\" version = \"0.5.0\" } } } Profiles \u00b6 Machine profiles specify the kernel, initrd, kernel args, Ignition Config, and other configs (e.g. templated Container Linux Config, Cloud-config, generic) used to network boot and provision a bare-metal machine. The profile below would PXE boot machines using a Fedora CoreOS kernel and initrd (see assets to learn about caching for speed), perform a disk install, reboot (first boot from disk), and use a Fedora CoreOS Config to generate an Ignition config to provision. // Fedora CoreOS profile resource \"matchbox_profile\" \"fedora-coreos-install\" { name = \"worker\" kernel = \"https://builds.coreos.fedoraproject.org/prod/streams/${var.os_stream}/builds/${var.os_version}/x86_64/fedora-coreos-${var.os_version}-live-kernel-x86_64\" initrd = [ \"--name main https://builds.coreos.fedoraproject.org/prod/streams/${var.os_stream}/builds/${var.os_version}/x86_64/fedora-coreos-${var.os_version}-live-initramfs.x86_64.img\" ] args = [ \"initrd=main\" , \"coreos.live.rootfs_url=https://builds.coreos.fedoraproject.org/prod/streams/${var.os_stream}/builds/${var.os_version}/x86_64/fedora-coreos-${var.os_version}-live-rootfs.x86_64.img\" , \"coreos.inst.install_dev=/dev/sda\" , \"coreos.inst.ignition_url=${var.matchbox_http_endpoint}/ignition?uuid=$${uuid}&mac=$${mac:hexhyp}\" ] raw_ignition = data.ct_config.worker.rendered } data \"ct_config\" \"worker\" { content = templatefile ( \"fcc/fedora-coreos.yaml\" , { ssh_authorized_key = var.ssh_authorized_key }) strict = true } Groups \u00b6 Matcher groups match machines based on labels like MAC, UUID, etc. to different profiles and templates in machine-specific values. The group below does not have a selector block, so any machines which network boot from Matchbox will match this group and be provisioned using the fedora-coreos-install profile. Machines are matched to the most specific matching group. // Default matcher group for machines resource \"matchbox_group\" \"default\" { name = \"default\" profile = matchbox_profile.fedora-coreos-install.name } Variables \u00b6 Some Terraform variables are used in the examples. A quick way to set their value is by creating a terraform.tfvars file. cp terraform.tfvars.example terraform.tfvars matchbox_http_endpoint = \"http://matchbox.example.com:8080\" matchbox_rpc_endpoint = \"matchbox.example.com:8081\" os_version = \"36.20220618.3.1\" ssh_authorized_key = \"YOUR_SSH_KEY\" Apply \u00b6 Initialize the Terraform workspace. Then plan and apply the resources. terraform init $ terraform apply Apply complete! Resources: 4 added, 0 changed, 0 destroyed. Matchbox serves configs to machines and respects query parameters, if you're interested: iPXE default - /ipxe Ignition default - /ignition Ignition post-install - /ignition?os=installed Network \u00b6 Matchbox can integrate with many on-premise network setups. It does not seek to be the DHCP server, TFTP server, or DNS server for the network. Instead, matchbox serves iPXE scripts as the entrypoint for provisioning network booted machines. PXE clients are supported by chainloading iPXE firmware. In the simplest case, an iPXE-enabled network can chain to Matchbox, # /var/www/html/ipxe/default.ipxe chain http://matchbox.foo:8080/boot.ipxe Read network-setup.md for the complete range of options. Network admins have a great amount of flexibility: May keep using existing DHCP, TFTP, and DNS services May configure subnets, architectures, or specific machines to delegate to matchbox May place matchbox behind a menu entry (timeout and default to matchbox) If you've never setup a PXE-enabled network before or you're trying to setup a home lab, checkout the quay.io/poseidon/dnsmasq container image copy-paste examples and see the section about proxy-DHCP . Boot \u00b6 Its time to network boot your machines. Use the BMC's remote management capabilities (may be vendor-specific) to set the boot device (on the next boot only) to PXE and power on each machine. $ ipmitool -H node1.example.com -U USER -P PASS power off $ ipmitool -H node1.example.com -U USER -P PASS chassis bootdev pxe $ ipmitool -H node1.example.com -U USER -P PASS power on Each machine should chainload iPXE, delegate to Matchbox, receive its iPXE config (or other supported configs) and begin the provisioning process. The examples assume machines are configured to boot from disk first and PXE only when requested, but you can write profiles for different cases. Once the install completes and the machine reboots, you can SSH. $ ssh core@node1.example.com To re-provision the machine for another purpose, run terraform apply and PXE boot machines again. Going Further \u00b6 Matchbox can be used to provision multi-node Fedora CoreOS or Flatcar Linux clusters at one or many on-premise sites if deployed in an HA way. Machines can be matched individually by MAC address, UUID, region, or other labels you choose. Installs can be made much faster by caching images in the built-in HTTP assets server. Ignition can be used to partition disks, create file systems, write systemd units, write networkd configs or regular files, and create users. Nodes can be network provisioned into a complete cluster system that meets your needs. For example, see Typhoon .","title":"Getting started"},{"location":"getting-started/#getting-started","text":"In this tutorial, we'll use matchbox with Terraform to provision Fedora CoreOS or Flatcar Linux machines. We'll install the matchbox service, setup a PXE network boot environment, and use Terraform configs to declare infrastructure and apply resources on matchbox .","title":"Getting started"},{"location":"getting-started/#matchbox","text":"Install matchbox on a host server or Kubernetes cluster. Generate TLS credentials and enable the gRPC API as directed. Save the ca.crt , client.crt , and client.key on your local machine (e.g. ~/.matchbox ). Installing on a Linux distro Installing on Kubernetes Running with docker Verify the matchbox read-only HTTP endpoints are accessible. $ curl http://matchbox.example.com:8080 matchbox Verify your TLS client certificate and key can be used to access the gRPC API. $ openssl s_client -connect matchbox.example.com:8081 \\ -CAfile ~/.matchbox/ca.crt \\ -cert ~/.matchbox/client.crt \\ -key ~/.matchbox/client.key","title":"matchbox"},{"location":"getting-started/#terraform","text":"Install Terraform v0.13+ on your system. $ terraform version Terraform v1.1.8","title":"Terraform"},{"location":"getting-started/#examples","text":"Clone the matchbox source. $ git clone https://github.com/poseidon/matchbox.git $ cd matchbox/examples/terraform Select from the Terraform examples . For example, fedora-coreos-install - PXE boot, install Fedora CoreOS to disk, reboot, and machines come up with your SSH authorized key set flatcar-install - PXE boot, install Flatcar Linux to disk, reboot, and machines come up with your SSH authorized key set These aren't exactly full clusters, but they show declarations and network provisioning. $ cd fedora-coreos-install # or flatcar-install Note Fedora CoreOS images are only served via HTTPS, so your iPXE firmware must be compiled to support HTTPS downloads. Let's review the terraform config and learn a bit about Matchbox.","title":"Examples"},{"location":"getting-started/#provider","text":"Matchbox is configured as a provider platform for bare-metal resources. // Configure the matchbox provider provider \"matchbox\" { endpoint = var.matchbox_rpc_endpoint client_cert = file ( \"~/.matchbox/client.crt\" ) client_key = file ( \"~/.matchbox/client.key\" ) ca = file ( \"~/.matchbox/ca.crt\" ) } terraform { required_providers { ct = { source = \"poseidon/ct\" version = \"0.10.0\" } matchbox = { source = \"poseidon/matchbox\" version = \"0.5.0\" } } }","title":"Provider"},{"location":"getting-started/#profiles","text":"Machine profiles specify the kernel, initrd, kernel args, Ignition Config, and other configs (e.g. templated Container Linux Config, Cloud-config, generic) used to network boot and provision a bare-metal machine. The profile below would PXE boot machines using a Fedora CoreOS kernel and initrd (see assets to learn about caching for speed), perform a disk install, reboot (first boot from disk), and use a Fedora CoreOS Config to generate an Ignition config to provision. // Fedora CoreOS profile resource \"matchbox_profile\" \"fedora-coreos-install\" { name = \"worker\" kernel = \"https://builds.coreos.fedoraproject.org/prod/streams/${var.os_stream}/builds/${var.os_version}/x86_64/fedora-coreos-${var.os_version}-live-kernel-x86_64\" initrd = [ \"--name main https://builds.coreos.fedoraproject.org/prod/streams/${var.os_stream}/builds/${var.os_version}/x86_64/fedora-coreos-${var.os_version}-live-initramfs.x86_64.img\" ] args = [ \"initrd=main\" , \"coreos.live.rootfs_url=https://builds.coreos.fedoraproject.org/prod/streams/${var.os_stream}/builds/${var.os_version}/x86_64/fedora-coreos-${var.os_version}-live-rootfs.x86_64.img\" , \"coreos.inst.install_dev=/dev/sda\" , \"coreos.inst.ignition_url=${var.matchbox_http_endpoint}/ignition?uuid=$${uuid}&mac=$${mac:hexhyp}\" ] raw_ignition = data.ct_config.worker.rendered } data \"ct_config\" \"worker\" { content = templatefile ( \"fcc/fedora-coreos.yaml\" , { ssh_authorized_key = var.ssh_authorized_key }) strict = true }","title":"Profiles"},{"location":"getting-started/#groups","text":"Matcher groups match machines based on labels like MAC, UUID, etc. to different profiles and templates in machine-specific values. The group below does not have a selector block, so any machines which network boot from Matchbox will match this group and be provisioned using the fedora-coreos-install profile. Machines are matched to the most specific matching group. // Default matcher group for machines resource \"matchbox_group\" \"default\" { name = \"default\" profile = matchbox_profile.fedora-coreos-install.name }","title":"Groups"},{"location":"getting-started/#variables","text":"Some Terraform variables are used in the examples. A quick way to set their value is by creating a terraform.tfvars file. cp terraform.tfvars.example terraform.tfvars matchbox_http_endpoint = \"http://matchbox.example.com:8080\" matchbox_rpc_endpoint = \"matchbox.example.com:8081\" os_version = \"36.20220618.3.1\" ssh_authorized_key = \"YOUR_SSH_KEY\"","title":"Variables"},{"location":"getting-started/#apply","text":"Initialize the Terraform workspace. Then plan and apply the resources. terraform init $ terraform apply Apply complete! Resources: 4 added, 0 changed, 0 destroyed. Matchbox serves configs to machines and respects query parameters, if you're interested: iPXE default - /ipxe Ignition default - /ignition Ignition post-install - /ignition?os=installed","title":"Apply"},{"location":"getting-started/#network","text":"Matchbox can integrate with many on-premise network setups. It does not seek to be the DHCP server, TFTP server, or DNS server for the network. Instead, matchbox serves iPXE scripts as the entrypoint for provisioning network booted machines. PXE clients are supported by chainloading iPXE firmware. In the simplest case, an iPXE-enabled network can chain to Matchbox, # /var/www/html/ipxe/default.ipxe chain http://matchbox.foo:8080/boot.ipxe Read network-setup.md for the complete range of options. Network admins have a great amount of flexibility: May keep using existing DHCP, TFTP, and DNS services May configure subnets, architectures, or specific machines to delegate to matchbox May place matchbox behind a menu entry (timeout and default to matchbox) If you've never setup a PXE-enabled network before or you're trying to setup a home lab, checkout the quay.io/poseidon/dnsmasq container image copy-paste examples and see the section about proxy-DHCP .","title":"Network"},{"location":"getting-started/#boot","text":"Its time to network boot your machines. Use the BMC's remote management capabilities (may be vendor-specific) to set the boot device (on the next boot only) to PXE and power on each machine. $ ipmitool -H node1.example.com -U USER -P PASS power off $ ipmitool -H node1.example.com -U USER -P PASS chassis bootdev pxe $ ipmitool -H node1.example.com -U USER -P PASS power on Each machine should chainload iPXE, delegate to Matchbox, receive its iPXE config (or other supported configs) and begin the provisioning process. The examples assume machines are configured to boot from disk first and PXE only when requested, but you can write profiles for different cases. Once the install completes and the machine reboots, you can SSH. $ ssh core@node1.example.com To re-provision the machine for another purpose, run terraform apply and PXE boot machines again.","title":"Boot"},{"location":"getting-started/#going-further","text":"Matchbox can be used to provision multi-node Fedora CoreOS or Flatcar Linux clusters at one or many on-premise sites if deployed in an HA way. Machines can be matched individually by MAC address, UUID, region, or other labels you choose. Installs can be made much faster by caching images in the built-in HTTP assets server. Ignition can be used to partition disks, create file systems, write systemd units, write networkd configs or regular files, and create users. Nodes can be network provisioned into a complete cluster system that meets your needs. For example, see Typhoon .","title":"Going Further"},{"location":"grub/","text":"GRUB2 netboot \u00b6 Use GRUB to network boot UEFI hardware. Requirements \u00b6 For local development, install the dependencies for libvirt with UEFI. UEFI with QEMU Ensure that you've gone through the matchbox with docker and matchbox guides and understand the basics. Containers \u00b6 Run matchbox according to matchbox with Docker , but mount the grub group example. Then start the poseidon/dnsmasq Docker image, which bundles a grub.efi . $ sudo docker run --rm --cap-add = NET_ADMIN quay.io/poseidon/dnsmasq -d -q --dhcp-range = 172 .17.0.43,172.17.0.99 --enable-tftp --tftp-root = /var/lib/tftpboot --dhcp-match = set:efi-bc,option:client-arch,7 --dhcp-boot = tag:efi-bc,grub.efi --dhcp-userclass = set:grub,GRUB2 --dhcp-boot = tag:grub, \"(http;matchbox.foo:8080)/grub\" , \"172.17.0.2\" --log-queries --log-dhcp --dhcp-option = 3 ,172.17.0.1 --dhcp-userclass = set:ipxe,iPXE --dhcp-boot = tag:pxe,undionly.kpxe --dhcp-boot = tag:ipxe,http://matchbox.foo:8080/boot.ipxe --address = /matchbox.foo/172.17.0.2 Client VM \u00b6 Create UEFI VM nodes which have known hardware attributes. $ sudo ./scripts/libvirt create-uefi Create a VM to verify the machine network boots. $ sudo virt-install --name uefi-test --boot = uefi,network --disk pool = default,size = 4 --network = bridge = docker0,model = e1000 --memory = 1024 --vcpus = 1 --os-type = linux --noautoconsole","title":"GRUB2 netboot"},{"location":"grub/#grub2-netboot","text":"Use GRUB to network boot UEFI hardware.","title":"GRUB2 netboot"},{"location":"grub/#requirements","text":"For local development, install the dependencies for libvirt with UEFI. UEFI with QEMU Ensure that you've gone through the matchbox with docker and matchbox guides and understand the basics.","title":"Requirements"},{"location":"grub/#containers","text":"Run matchbox according to matchbox with Docker , but mount the grub group example. Then start the poseidon/dnsmasq Docker image, which bundles a grub.efi . $ sudo docker run --rm --cap-add = NET_ADMIN quay.io/poseidon/dnsmasq -d -q --dhcp-range = 172 .17.0.43,172.17.0.99 --enable-tftp --tftp-root = /var/lib/tftpboot --dhcp-match = set:efi-bc,option:client-arch,7 --dhcp-boot = tag:efi-bc,grub.efi --dhcp-userclass = set:grub,GRUB2 --dhcp-boot = tag:grub, \"(http;matchbox.foo:8080)/grub\" , \"172.17.0.2\" --log-queries --log-dhcp --dhcp-option = 3 ,172.17.0.1 --dhcp-userclass = set:ipxe,iPXE --dhcp-boot = tag:pxe,undionly.kpxe --dhcp-boot = tag:ipxe,http://matchbox.foo:8080/boot.ipxe --address = /matchbox.foo/172.17.0.2","title":"Containers"},{"location":"grub/#client-vm","text":"Create UEFI VM nodes which have known hardware attributes. $ sudo ./scripts/libvirt create-uefi Create a VM to verify the machine network boots. $ sudo virt-install --name uefi-test --boot = uefi,network --disk pool = default,size = 4 --network = bridge = docker0,model = e1000 --memory = 1024 --vcpus = 1 --os-type = linux --noautoconsole","title":"Client VM"},{"location":"machine-lifecycle/","text":"Lifecycle of a physical machine \u00b6 About boot environment \u00b6 Physical machines network boot in an network boot environment with DHCP/TFTP/DNS services or with poseidon/dnsmasq . matchbox serves iPXE or GRUB configs via HTTP to machines based on Group selectors (e.g. UUID, MAC, region, etc.) and machine Profiles. Kernel and initrd images are fetched and booted with Ignition to install CoreOS Container Linux. The \"first boot\" Ignition config if fetched and Container Linux is installed. Container Linux boots (\"first boot\" from disk) and runs Ignition to provision its disk with systemd units, files, keys, and more to become a cluster node. Systemd units may fetch metadata from a remote source if needed. Coordinated auto-updates are enabled. Systems like fleet or Kubernetes coordinate container services. IPMI, vendor utilities, or first-boot are used to re-provision machines into new roles. Machine lifecycle \u00b6","title":"Machine Lifecycle"},{"location":"machine-lifecycle/#lifecycle-of-a-physical-machine","text":"","title":"Lifecycle of a physical machine"},{"location":"machine-lifecycle/#about-boot-environment","text":"Physical machines network boot in an network boot environment with DHCP/TFTP/DNS services or with poseidon/dnsmasq . matchbox serves iPXE or GRUB configs via HTTP to machines based on Group selectors (e.g. UUID, MAC, region, etc.) and machine Profiles. Kernel and initrd images are fetched and booted with Ignition to install CoreOS Container Linux. The \"first boot\" Ignition config if fetched and Container Linux is installed. Container Linux boots (\"first boot\" from disk) and runs Ignition to provision its disk with systemd units, files, keys, and more to become a cluster node. Systemd units may fetch metadata from a remote source if needed. Coordinated auto-updates are enabled. Systems like fleet or Kubernetes coordinate container services. IPMI, vendor utilities, or first-boot are used to re-provision machines into new roles.","title":"About boot environment"},{"location":"machine-lifecycle/#machine-lifecycle","text":"","title":"Machine lifecycle"},{"location":"matchbox/","text":"matchbox \u00b6 matchbox is an HTTP and gRPC service that renders signed Ignition configs , cloud-configs , network boot configs, and metadata to machines to create CoreOS Container Linux clusters. matchbox maintains Group definitions which match machines to profiles based on labels (e.g. MAC address, UUID, stage, region). A Profile is a named set of config templates (e.g. iPXE, GRUB, Ignition config, Cloud-Config, generic configs). The aim is to use Container Linux's early-boot capabilities to provision Container Linux machines. Network boot endpoints provide PXE, iPXE, GRUB support. matchbox can be run a binary or as a container. Getting started \u00b6 Get started running matchbox on your Linux machine, with Docker. matchbox with Docker Flags \u00b6 See configuration flags and variables. API \u00b6 HTTP API gRPC API Data \u00b6 A Store stores machine Groups, Profiles, and associated Ignition configs, cloud-configs, and generic configs. By default, matchbox uses a FileStore to search a -data-path for these resources. Prepare /var/lib/matchbox with groups , profile , ignition , cloud , and generic subdirectories. You may wish to keep these files under version control. /var/lib/matchbox \u251c\u2500\u2500 cloud \u2502 \u251c\u2500\u2500 cloud.yaml.tmpl \u2502 \u2514\u2500\u2500 worker.sh.tmpl \u251c\u2500\u2500 ignition \u2502 \u2514\u2500\u2500 raw.ign \u2502 \u2514\u2500\u2500 etcd.yaml.tmpl \u2502 \u2514\u2500\u2500 simple.yaml.tmpl \u251c\u2500\u2500 generic \u2502 \u2514\u2500\u2500 config.yaml \u2502 \u2514\u2500\u2500 setup.cfg \u2502 \u2514\u2500\u2500 datacenter-1.tmpl \u251c\u2500\u2500 groups \u2502 \u2514\u2500\u2500 default.json \u2502 \u2514\u2500\u2500 node1.json \u2502 \u2514\u2500\u2500 us-central1-a.json \u2514\u2500\u2500 profiles \u2514\u2500\u2500 etcd.json \u2514\u2500\u2500 worker.json The examples directory is a valid data directory with some pre-defined configs. Note that examples/groups contains many possible groups in nested directories for demo purposes (tutorials pick one to mount). Your machine groups should be kept directly inside the groups directory as shown above. Profiles \u00b6 Profiles reference an Ignition config, Cloud-Config, and/or generic config by name and define network boot settings. { \"id\" : \"etcd\" , \"name\" : \"Container Linux with etcd2\" , \"cloud_id\" : \"\" , \"ignition_id\" : \"etcd.yaml\" , \"generic_id\" : \"some-service.cfg\" , \"boot\" : { \"kernel\" : \"/assets/coreos/1967.3.0/coreos_production_pxe.vmlinuz\" , \"initrd\" : [ \"/assets/coreos/1967.3.0/coreos_production_pxe_image.cpio.gz\" ], \"args\" : [ \"coreos.config.url=http://matchbox.foo:8080/ignition?uuid=${uuid}&mac=${mac:hexhyp}\" , \"coreos.first_boot=yes\" , \"coreos.autologin\" ] }, } The \"boot\" settings will be used to render configs to network boot programs such as iPXE or GRUB. You may reference remote kernel and initrd assets or local assets . To use Ignition, set the coreos.config.url kernel option to reference the matchbox Ignition endpoint , which will render the ignition_id file. Be sure to add the coreos.first_boot option as well. To use cloud-config, set the cloud-config-url kernel option to reference the matchbox Cloud-Config endpoint , which will render the cloud_id file. Groups \u00b6 Groups define selectors which match zero or more machines. Machine(s) matching a group will boot and provision according to the group's Profile . Create a group definition with a Profile to be applied, selectors for matching machines, and any metadata needed to render templated configs. For example /var/lib/matchbox/groups/node1.json matches a single machine with MAC address 52:54:00:89:d8:10 . # /var/lib/ma t chbox/groups/ n ode 1. jso n { \"name\" : \"node1\" , \"profile\" : \"etcd\" , \"selector\" : { \"mac\" : \"52:54:00:89:d8:10\" }, \"metadata\" : { \"fleet_metadata\" : \"role=etcd,name=node1\" , \"etcd_name\" : \"node1\" , \"etcd_initial_cluster\" : \"node1=http://node1.example.com:2380,node2=http://node2.example.com:2380,node3=http://node3.example.com:2380\" } } Meanwhile, /var/lib/matchbox/groups/proxy.json acts as the default machine group since it has no selectors. { \"name\": \"etcd-proxy\", \"profile\": \"etcd-proxy\", \"metadata\": { \"fleet_metadata\": \"role=etcd-proxy\", \"etcd_initial_cluster\": \"node1=http://node1.example.com:2380,node2=http://node2.example.com:2380,node3=http://node3.example.com:2380\" } } For example, a request to /ignition?mac=52:54:00:89:d8:10 would render the Ignition template in the \"etcd\" Profile , with the machine group's metadata. A request to /ignition would match the default group (which has no selectors) and render the Ignition in the \"etcd-proxy\" Profile. Avoid defining multiple default groups as resolution will not be deterministic. Reserved selectors \u00b6 Group selectors can use any key/value pairs you find useful. However, several labels have a defined purpose and will be normalized or parsed specially. uuid - machine UUID mac - network interface physical address (normalized MAC address) hostname - hostname reported by a network boot program serial - serial reported by a network boot program Config templates \u00b6 Profiles can reference various templated configs. Ignition JSON configs can be generated from Container Linux Config template files. Cloud-Config templates files can be used to render a script or Cloud-Config. Generic template files can be used to render arbitrary untyped configs (experimental). Each template may contain Go template elements which will be rendered with machine group metadata, selectors, and query params. For details and examples: Container Linux Config Cloud-Config Variables \u00b6 Within Container Linux Config templates, Cloud-Config templates, or generic templates, you can use group metadata, selectors, or request-scoped query params. For example, a request /generic?mac=52-54-00-89-d8-10&foo=some-param&bar=b would match the node1.json machine group shown above. If the group's profile (\"etcd\") referenced a generic template, the following variables could be used. # Untyped generic config file # Selector {{.mac}} # 52:54:00:89:d8:10 (normalized) # Metadata {{.etcd_name}} # node1 {{.fleet_metadata}} # role=etcd,name=node1 # Query {{.request.query.mac}} # 52:54:00:89:d8:10 (normalized) {{.request.query.foo}} # some-param {{.request.query.bar}} # b # Special Addition {{.request.raw_query}} # mac=52:54:00:89:d8:10&foo=some-param&bar=b Note that .request is reserved for these purposes so group metadata with data nested under a top level \"request\" key will be overwritten. Assets \u00b6 matchbox can serve -assets-path static assets at /assets . This is helpful for reducing bandwidth usage when serving the kernel and initrd to network booted machines. The default assets-path is /var/lib/matchbox/assets or you can pass -assets-path=\"\" to disable asset serving. matchbox.foo/assets/ \u2514\u2500\u2500 coreos \u2514\u2500\u2500 VERSION \u251c\u2500\u2500 coreos_production_pxe.vmlinuz \u2514\u2500\u2500 coreos_production_pxe_image.cpio.gz For example, a Profile might refer to a local asset /assets/coreos/VERSION/coreos_production_pxe.vmlinuz instead of http://stable.release.core-os.net/amd64-usr/VERSION/coreos_production_pxe.vmlinuz . See the get-fedora-coreos or get-flatcar scripts to quickly download, verify, and place image assets. Network \u00b6 matchbox does not implement or exec a DHCP/TFTP server. Read network setup or use the poseidon/dnsmasq image if you need a quick DHCP, proxyDHCP, TFTP, or DNS setup. Going further \u00b6 gRPC API Usage Metadata OpenPGP Signing","title":"Concepts"},{"location":"matchbox/#matchbox","text":"matchbox is an HTTP and gRPC service that renders signed Ignition configs , cloud-configs , network boot configs, and metadata to machines to create CoreOS Container Linux clusters. matchbox maintains Group definitions which match machines to profiles based on labels (e.g. MAC address, UUID, stage, region). A Profile is a named set of config templates (e.g. iPXE, GRUB, Ignition config, Cloud-Config, generic configs). The aim is to use Container Linux's early-boot capabilities to provision Container Linux machines. Network boot endpoints provide PXE, iPXE, GRUB support. matchbox can be run a binary or as a container.","title":"matchbox"},{"location":"matchbox/#getting-started","text":"Get started running matchbox on your Linux machine, with Docker. matchbox with Docker","title":"Getting started"},{"location":"matchbox/#flags","text":"See configuration flags and variables.","title":"Flags"},{"location":"matchbox/#api","text":"HTTP API gRPC API","title":"API"},{"location":"matchbox/#data","text":"A Store stores machine Groups, Profiles, and associated Ignition configs, cloud-configs, and generic configs. By default, matchbox uses a FileStore to search a -data-path for these resources. Prepare /var/lib/matchbox with groups , profile , ignition , cloud , and generic subdirectories. You may wish to keep these files under version control. /var/lib/matchbox \u251c\u2500\u2500 cloud \u2502 \u251c\u2500\u2500 cloud.yaml.tmpl \u2502 \u2514\u2500\u2500 worker.sh.tmpl \u251c\u2500\u2500 ignition \u2502 \u2514\u2500\u2500 raw.ign \u2502 \u2514\u2500\u2500 etcd.yaml.tmpl \u2502 \u2514\u2500\u2500 simple.yaml.tmpl \u251c\u2500\u2500 generic \u2502 \u2514\u2500\u2500 config.yaml \u2502 \u2514\u2500\u2500 setup.cfg \u2502 \u2514\u2500\u2500 datacenter-1.tmpl \u251c\u2500\u2500 groups \u2502 \u2514\u2500\u2500 default.json \u2502 \u2514\u2500\u2500 node1.json \u2502 \u2514\u2500\u2500 us-central1-a.json \u2514\u2500\u2500 profiles \u2514\u2500\u2500 etcd.json \u2514\u2500\u2500 worker.json The examples directory is a valid data directory with some pre-defined configs. Note that examples/groups contains many possible groups in nested directories for demo purposes (tutorials pick one to mount). Your machine groups should be kept directly inside the groups directory as shown above.","title":"Data"},{"location":"matchbox/#profiles","text":"Profiles reference an Ignition config, Cloud-Config, and/or generic config by name and define network boot settings. { \"id\" : \"etcd\" , \"name\" : \"Container Linux with etcd2\" , \"cloud_id\" : \"\" , \"ignition_id\" : \"etcd.yaml\" , \"generic_id\" : \"some-service.cfg\" , \"boot\" : { \"kernel\" : \"/assets/coreos/1967.3.0/coreos_production_pxe.vmlinuz\" , \"initrd\" : [ \"/assets/coreos/1967.3.0/coreos_production_pxe_image.cpio.gz\" ], \"args\" : [ \"coreos.config.url=http://matchbox.foo:8080/ignition?uuid=${uuid}&mac=${mac:hexhyp}\" , \"coreos.first_boot=yes\" , \"coreos.autologin\" ] }, } The \"boot\" settings will be used to render configs to network boot programs such as iPXE or GRUB. You may reference remote kernel and initrd assets or local assets . To use Ignition, set the coreos.config.url kernel option to reference the matchbox Ignition endpoint , which will render the ignition_id file. Be sure to add the coreos.first_boot option as well. To use cloud-config, set the cloud-config-url kernel option to reference the matchbox Cloud-Config endpoint , which will render the cloud_id file.","title":"Profiles"},{"location":"matchbox/#groups","text":"Groups define selectors which match zero or more machines. Machine(s) matching a group will boot and provision according to the group's Profile . Create a group definition with a Profile to be applied, selectors for matching machines, and any metadata needed to render templated configs. For example /var/lib/matchbox/groups/node1.json matches a single machine with MAC address 52:54:00:89:d8:10 . # /var/lib/ma t chbox/groups/ n ode 1. jso n { \"name\" : \"node1\" , \"profile\" : \"etcd\" , \"selector\" : { \"mac\" : \"52:54:00:89:d8:10\" }, \"metadata\" : { \"fleet_metadata\" : \"role=etcd,name=node1\" , \"etcd_name\" : \"node1\" , \"etcd_initial_cluster\" : \"node1=http://node1.example.com:2380,node2=http://node2.example.com:2380,node3=http://node3.example.com:2380\" } } Meanwhile, /var/lib/matchbox/groups/proxy.json acts as the default machine group since it has no selectors. { \"name\": \"etcd-proxy\", \"profile\": \"etcd-proxy\", \"metadata\": { \"fleet_metadata\": \"role=etcd-proxy\", \"etcd_initial_cluster\": \"node1=http://node1.example.com:2380,node2=http://node2.example.com:2380,node3=http://node3.example.com:2380\" } } For example, a request to /ignition?mac=52:54:00:89:d8:10 would render the Ignition template in the \"etcd\" Profile , with the machine group's metadata. A request to /ignition would match the default group (which has no selectors) and render the Ignition in the \"etcd-proxy\" Profile. Avoid defining multiple default groups as resolution will not be deterministic.","title":"Groups"},{"location":"matchbox/#reserved-selectors","text":"Group selectors can use any key/value pairs you find useful. However, several labels have a defined purpose and will be normalized or parsed specially. uuid - machine UUID mac - network interface physical address (normalized MAC address) hostname - hostname reported by a network boot program serial - serial reported by a network boot program","title":"Reserved selectors"},{"location":"matchbox/#config-templates","text":"Profiles can reference various templated configs. Ignition JSON configs can be generated from Container Linux Config template files. Cloud-Config templates files can be used to render a script or Cloud-Config. Generic template files can be used to render arbitrary untyped configs (experimental). Each template may contain Go template elements which will be rendered with machine group metadata, selectors, and query params. For details and examples: Container Linux Config Cloud-Config","title":"Config templates"},{"location":"matchbox/#variables","text":"Within Container Linux Config templates, Cloud-Config templates, or generic templates, you can use group metadata, selectors, or request-scoped query params. For example, a request /generic?mac=52-54-00-89-d8-10&foo=some-param&bar=b would match the node1.json machine group shown above. If the group's profile (\"etcd\") referenced a generic template, the following variables could be used. # Untyped generic config file # Selector {{.mac}} # 52:54:00:89:d8:10 (normalized) # Metadata {{.etcd_name}} # node1 {{.fleet_metadata}} # role=etcd,name=node1 # Query {{.request.query.mac}} # 52:54:00:89:d8:10 (normalized) {{.request.query.foo}} # some-param {{.request.query.bar}} # b # Special Addition {{.request.raw_query}} # mac=52:54:00:89:d8:10&foo=some-param&bar=b Note that .request is reserved for these purposes so group metadata with data nested under a top level \"request\" key will be overwritten.","title":"Variables"},{"location":"matchbox/#assets","text":"matchbox can serve -assets-path static assets at /assets . This is helpful for reducing bandwidth usage when serving the kernel and initrd to network booted machines. The default assets-path is /var/lib/matchbox/assets or you can pass -assets-path=\"\" to disable asset serving. matchbox.foo/assets/ \u2514\u2500\u2500 coreos \u2514\u2500\u2500 VERSION \u251c\u2500\u2500 coreos_production_pxe.vmlinuz \u2514\u2500\u2500 coreos_production_pxe_image.cpio.gz For example, a Profile might refer to a local asset /assets/coreos/VERSION/coreos_production_pxe.vmlinuz instead of http://stable.release.core-os.net/amd64-usr/VERSION/coreos_production_pxe.vmlinuz . See the get-fedora-coreos or get-flatcar scripts to quickly download, verify, and place image assets.","title":"Assets"},{"location":"matchbox/#network","text":"matchbox does not implement or exec a DHCP/TFTP server. Read network setup or use the poseidon/dnsmasq image if you need a quick DHCP, proxyDHCP, TFTP, or DNS setup.","title":"Network"},{"location":"matchbox/#going-further","text":"gRPC API Usage Metadata OpenPGP Signing","title":"Going further"},{"location":"network-booting/","text":"Network boot environments \u00b6 This guide reviews network boot protocols and the different ways client machines can be PXE booted. PXE \u00b6 The Preboot eXecution Environment (PXE) defines requirements for consistent, hardware-independent network-based machine booting and configuration. Formally, PXE specifies pre-boot protocol services that client NIC firmware must provide (DHCP, TFTP, UDP/IP), specifies boot firmware requirements, and defines a client-server protocol for obtaining a network boot program (NBP) which automates OS installation and configuration. At power-on, if a client machine's BIOS or UEFI boot firmware is set to perform network booting, the network interface card's PXE firmware broadcasts a DHCPDISCOVER packet identifying itself as a PXEClient to the network environment. The network environment can be set up in a number of ways, which we'll discuss. In the simplest, a PXE-enabled DHCP Server responds with a DHCPOFFER with Options, which include a TFTP server IP (\"next server\") and the name of an NBP (\"boot filename\") to download (e.g. pxelinux.0). PXE firmware then downloads the NBP over TFTP and starts it. Finally, the NBP loads configs, scripts, and/or images it requires to run an OS. Network boot programs \u00b6 Machines can be booted and configured with CoreOS Container Linux using several network boot programs and approaches. Let's review them. If you're new to network booting or unsure which to choose, iPXE is a reasonable and flexible choice. PXELINUX \u00b6 PXELINUX is a common network boot program which loads a config file from mybootdir/pxelinux.cfg/ over TFTP. The file is chosen based on the client's UUID, MAC address, IP address, or a default. $ mybootdir/pxelinux.cfg/b8945908-d6a6-41a9-611d-74a6ab80b83d $ mybootdir/pxelinux.cfg/default Here is an example PXE config file which boots a Container Linux image hosted on the TFTP server. default coreos prompt 1 timeout 15 display boot.msg label coreos menu default kernel coreos_production_pxe.vmlinuz append initrd=coreos_production_pxe_image.cpio.gz cloud-config-url=http://example.com/pxe-cloud-config.yml PXELINUX then downloads the specified kernel and init RAM filesystem images with TFTP. This approach has a number of drawbacks. TFTP can be slow, managing config files can be tedious, and using different ignition or cloud configs on different machines requires separate pxelinux configs. These limitations spurred the development of various enhancements to PXE, discussed next. iPXE \u00b6 iPXE is an enhanced implementation of the PXE client firmware and a network boot program which uses iPXE scripts rather than config files and can download scripts and images with HTTP. A DHCPOFFER to iPXE client firmware specifies an HTTP boot script such as http://matchbox.foo/boot.ipxe . Here is an example iPXE script for booting the remote Container Linux stable image. #!ipxe set base-url http://stable.release.core-os.net/amd64-usr/current kernel ${base-url}/coreos_production_pxe.vmlinuz cloud-config-url=http://provisioner.example.net/cloud-config.yml initrd ${base-url}/coreos_production_pxe_image.cpio.gz boot A TFTP server is used only to provide the undionly.kpxe boot program to older PXE firmware in order to bootstrap into iPXE. CoreOS matchbox can render signed iPXE scripts to machines based on their hardware attributes. Setup involves configuring your DHCP server to point iPXE clients to the matchbox iPXE endpoint . DHCP \u00b6 Many networks have DHCP services which are impractical to modify or disable. Company DHCP servers are governed by network admin policies and home/office networks often have routers running a DHCP service which cannot supply PXE options to PXE clients. To address this, PXE client firmware listens for DHCPOFFERs from a non-PXE DHCP server and a PXE-enabled proxyDHCP server configured to respond with the next server and boot filename only. Client firmware combines the two responses as if they had come from a single PXE-enabled DHCP server.","title":"Network Boot Environment"},{"location":"network-booting/#network-boot-environments","text":"This guide reviews network boot protocols and the different ways client machines can be PXE booted.","title":"Network boot environments"},{"location":"network-booting/#pxe","text":"The Preboot eXecution Environment (PXE) defines requirements for consistent, hardware-independent network-based machine booting and configuration. Formally, PXE specifies pre-boot protocol services that client NIC firmware must provide (DHCP, TFTP, UDP/IP), specifies boot firmware requirements, and defines a client-server protocol for obtaining a network boot program (NBP) which automates OS installation and configuration. At power-on, if a client machine's BIOS or UEFI boot firmware is set to perform network booting, the network interface card's PXE firmware broadcasts a DHCPDISCOVER packet identifying itself as a PXEClient to the network environment. The network environment can be set up in a number of ways, which we'll discuss. In the simplest, a PXE-enabled DHCP Server responds with a DHCPOFFER with Options, which include a TFTP server IP (\"next server\") and the name of an NBP (\"boot filename\") to download (e.g. pxelinux.0). PXE firmware then downloads the NBP over TFTP and starts it. Finally, the NBP loads configs, scripts, and/or images it requires to run an OS.","title":"PXE"},{"location":"network-booting/#network-boot-programs","text":"Machines can be booted and configured with CoreOS Container Linux using several network boot programs and approaches. Let's review them. If you're new to network booting or unsure which to choose, iPXE is a reasonable and flexible choice.","title":"Network boot programs"},{"location":"network-booting/#pxelinux","text":"PXELINUX is a common network boot program which loads a config file from mybootdir/pxelinux.cfg/ over TFTP. The file is chosen based on the client's UUID, MAC address, IP address, or a default. $ mybootdir/pxelinux.cfg/b8945908-d6a6-41a9-611d-74a6ab80b83d $ mybootdir/pxelinux.cfg/default Here is an example PXE config file which boots a Container Linux image hosted on the TFTP server. default coreos prompt 1 timeout 15 display boot.msg label coreos menu default kernel coreos_production_pxe.vmlinuz append initrd=coreos_production_pxe_image.cpio.gz cloud-config-url=http://example.com/pxe-cloud-config.yml PXELINUX then downloads the specified kernel and init RAM filesystem images with TFTP. This approach has a number of drawbacks. TFTP can be slow, managing config files can be tedious, and using different ignition or cloud configs on different machines requires separate pxelinux configs. These limitations spurred the development of various enhancements to PXE, discussed next.","title":"PXELINUX"},{"location":"network-booting/#ipxe","text":"iPXE is an enhanced implementation of the PXE client firmware and a network boot program which uses iPXE scripts rather than config files and can download scripts and images with HTTP. A DHCPOFFER to iPXE client firmware specifies an HTTP boot script such as http://matchbox.foo/boot.ipxe . Here is an example iPXE script for booting the remote Container Linux stable image. #!ipxe set base-url http://stable.release.core-os.net/amd64-usr/current kernel ${base-url}/coreos_production_pxe.vmlinuz cloud-config-url=http://provisioner.example.net/cloud-config.yml initrd ${base-url}/coreos_production_pxe_image.cpio.gz boot A TFTP server is used only to provide the undionly.kpxe boot program to older PXE firmware in order to bootstrap into iPXE. CoreOS matchbox can render signed iPXE scripts to machines based on their hardware attributes. Setup involves configuring your DHCP server to point iPXE clients to the matchbox iPXE endpoint .","title":"iPXE"},{"location":"network-booting/#dhcp","text":"Many networks have DHCP services which are impractical to modify or disable. Company DHCP servers are governed by network admin policies and home/office networks often have routers running a DHCP service which cannot supply PXE options to PXE clients. To address this, PXE client firmware listens for DHCPOFFERs from a non-PXE DHCP server and a PXE-enabled proxyDHCP server configured to respond with the next server and boot filename only. Client firmware combines the two responses as if they had come from a single PXE-enabled DHCP server.","title":"DHCP"},{"location":"network-setup/","text":"Network setup \u00b6 This guide shows how to create a DHCP/TFTP/DNS network boot environment to boot and provision BIOS/PXE, iPXE, or UEFI client machines. Matchbox serves iPXE scripts over HTTP to serve as the entrypoint for provisioning clusters. It does not implement or exec a DHCP, TFTP, or DNS server. Instead, configure your network environment to point to Matchbox or use the convenient quay.io/poseidon/dnsmasq container image (used in local QEMU/KVM setup). Note : These are just suggestions. Your network administrator or system administrator should choose the right network setup for your company. Requirements \u00b6 Client hardware must have a network interface which supports PXE or iPXE. Goals \u00b6 Add a DNS name which resolves to a matchbox deploy. Chainload BIOS clients (legacy PXE) to iPXE (undionly.kpxe) Chainload UEFI clients to iPXE (ipxe.efi) Point iPXE clients to http://matchbox.example.com:port/boot.ipxe Point GRUB clients to http://matchbox.example.com:port/grub Setup \u00b6 Many companies already have DHCP/TFTP configured to \"PXE-boot\" PXE/iPXE clients. In this case, machines (or a subset of machines) can be made to chainload from chain http://matchbox.example.com:port/boot.ipxe . Older PXE clients can be made to chainload into iPXE to be able to fetch subsequent configs via HTTP. On simpler networks, such as what a developer might have at home, a relatively inflexible DHCP server may be in place, with no TFTP server. In this case, a proxy DHCP server can be run alongside a non-PXE capable DHCP server. This diagram can point you to the right section(s) of this document. The setup of DHCP, TFTP, and DNS services on a network varies greatly. If you wish to use Docker to quickly run DHCP, proxyDHCP TFTP, or DNS services, use poseidon/dnsmasq . DNS \u00b6 Add a DNS entry (e.g. matchbox.example.com , provisoner.mycompany-internal ) that resolves to a deployment of the CoreOS matchbox service from machines you intend to boot and provision. $ dig matchbox.example.com If you deployed matchbox to a known IP address (e.g. dedicated host, load balanced endpoint, Kubernetes NodePort) and use dnsmasq , a domain name to IPv4/IPv6 address mapping could be added to the /etc/dnsmasq.conf . # dnsmasq.conf address=/matchbox.example.com/172.18.0.2 iPXE \u00b6 Networks which already run DHCP and TFTP services to network boot PXE/iPXE clients can add an iPXE config to delegate or chain to the matchbox service's iPXE entrypoint. # /var/www/html/ipxe/default.ipxe chain http://matchbox.example.com:8080/boot.ipxe You can chainload from a menu entry or use other iPXE commands if you need to do more than simple delegation. PXE-enabled DHCP \u00b6 Configure your DHCP server to supply options to older PXE client firmware to specify the location of an iPXE or GRUB network boot program on your TFTP server. Send clients to the matchbox iPXE script or GRUB config endpoints. Here is an example /etc/dnsmasq.conf : dhcp-range = 192.168.1.1,192.168.1.254,30m enable-tftp tftp-root = /var/lib/tftpboot # Legacy PXE dhcp-match = set:bios,option:client-arch,0 dhcp-boot = tag:bios,undionly.kpxe # UEFI dhcp-match = set:efi32,option:client-arch,6 dhcp-boot = tag:efi32,ipxe.efi dhcp-match = set:efibc,option:client-arch,7 dhcp-boot = tag:efibc,ipxe.efi dhcp-match = set:efi64,option:client-arch,9 dhcp-boot = tag:efi64,ipxe.efi # iPXE - chainload to matchbox ipxe boot script dhcp-userclass = set:ipxe,iPXE dhcp-boot = tag:ipxe,http://matchbox.example.com:8080/boot.ipxe # verbose log-queries log-dhcp # static DNS assignments address = /matchbox.example.com/192.168.1.100 # (optional) disable DNS and specify alternate # port=0 # dhcp-option=6,192.168.1.100 Add ipxe.efi and unidonly.kpxe to your tftp-root (e.g. /var/lib/tftpboot ). $ sudo systemctl start dnsmasq $ sudo firewall-cmd --add-service = dhcp --add-service = tftp [ --add-service = dns ] $ sudo firewall-cmd --list-services See dnsmasq below to run dnsmasq with a container. Proxy-DHCP \u00b6 Alternately, a proxy-DHCP server can be run alongside an existing non-PXE DHCP server. The proxy DHCP server provides only the next server and boot filename Options, leaving IP allocation to the DHCP server. Clients listen for both DHCP offers and merge the responses as though they had come from one PXE-enabled DHCP server. Example /etc/dnsmasq.conf : dhcp-range = 192.168.1.1,proxy,255.255.255.0 enable-tftp tftp-root = /var/lib/tftpboot # if request comes from older PXE ROM, chainload to iPXE (via TFTP) pxe-service = tag:#ipxe,x86PC,\"PXE chainload to iPXE\",undionly.kpxe # if request comes from iPXE user class, set tag \"ipxe\" dhcp-userclass = set:ipxe,iPXE # point ipxe tagged requests to the matchbox iPXE boot script (via HTTP) pxe-service = tag:ipxe,x86PC,\"iPXE\",http://matchbox.example.com:8080/boot.ipxe # verbose log-queries log-dhcp Add unidonly.kpxe (and undionly.kpxe.0 if using dnsmasq) to your tftp-root (e.g. /var/lib/tftpboot ). $ sudo systemctl start dnsmasq $ sudo firewall-cmd --add-service = dhcp --add-service = tftp [ --add-service = dns ] $ sudo firewall-cmd --list-services See dnsmasq below to run dnsmasq with a container. Configurable TFTP \u00b6 If your DHCP server is configured to network boot PXE clients (but not iPXE clients), add a pxelinux.cfg to serve an iPXE kernel image and append commands. Example /var/lib/tftpboot/pxelinux.cfg/default : timeout 10 default iPXE LABEL iPXE KERNEL ipxe.lkrn APPEND dhcp && chain http://matchbox.example.com:8080/boot.ipxe Add ipxe.lkrn to /var/lib/tftpboot (see iPXE docs ). poseidon/dnsmasq \u00b6 The quay.io/poseidon/dnsmasq container image can run DHCP, TFTP, and DNS services via docker. The image bundles ipxe.efi , undionly.kpxe , and grub.efi for convenience. See contrib/dnsmasq for details. Run DHCP, TFTP, and DNS on the host's network: sudo docker run --rm --cap-add = NET_ADMIN --net = host quay.io/poseidon/dnsmasq \\ -d -q \\ --dhcp-range = 192 .168.1.3,192.168.1.254 \\ --enable-tftp --tftp-root = /var/lib/tftpboot \\ --dhcp-match = set:bios,option:client-arch,0 \\ --dhcp-boot = tag:bios,undionly.kpxe \\ --dhcp-match = set:efi32,option:client-arch,6 \\ --dhcp-boot = tag:efi32,ipxe.efi \\ --dhcp-match = set:efibc,option:client-arch,7 \\ --dhcp-boot = tag:efibc,ipxe.efi \\ --dhcp-match = set:efi64,option:client-arch,9 \\ --dhcp-boot = tag:efi64,ipxe.efi \\ --dhcp-userclass = set:ipxe,iPXE \\ --dhcp-boot = tag:ipxe,http://matchbox.example.com:8080/boot.ipxe \\ --address = /matchbox.example.com/192.168.1.2 \\ --log-queries \\ --log-dhcp Run a proxy-DHCP and TFTP service on the host's network: sudo docker run --rm --cap-add = NET_ADMIN --net = host quay.io/poseidon/dnsmasq \\ -d -q \\ --dhcp-range = 192 .168.1.1,proxy,255.255.255.0 \\ --enable-tftp --tftp-root = /var/lib/tftpboot \\ --dhcp-userclass = set:ipxe,iPXE \\ --pxe-service = tag:#ipxe,x86PC, \"PXE chainload to iPXE\" ,undionly.kpxe \\ --pxe-service = tag:ipxe,x86PC, \"iPXE\" ,http://matchbox.example.com:8080/boot.ipxe \\ --pxe-service = tag:#ipxe,X86-64_EFI, \"PXE chainload to iPXE UEFI\" ,ipxe.efi \\ --pxe-service = tag:ipxe,X86-64_EFI, \"iPXE UEFI\" ,http:///matchbox.example.com:8080/boot.ipxe \\ --log-queries \\ --log-dhcp Be sure to allow enabled services in your firewall configuration. $ sudo firewall-cmd --add-service = dhcp --add-service = tftp --add-service = dns UEFI \u00b6 Development \u00b6 Install the dependencies for QEMU with UEFI . Walk through the getting-started-with-docker tutorial. Launch client VMs using create-uefi . Create UEFI QEMU/KVM VMs attached to the docker0 bridge. $ sudo ./scripts/libvirt create-uefi UEFI clients should chainload ipxe.efi , load iPXE and Ignition configs from Matchbox, and Container Linux should boot as usual. Troubleshooting \u00b6 See troubleshooting .","title":"Network Setup"},{"location":"network-setup/#network-setup","text":"This guide shows how to create a DHCP/TFTP/DNS network boot environment to boot and provision BIOS/PXE, iPXE, or UEFI client machines. Matchbox serves iPXE scripts over HTTP to serve as the entrypoint for provisioning clusters. It does not implement or exec a DHCP, TFTP, or DNS server. Instead, configure your network environment to point to Matchbox or use the convenient quay.io/poseidon/dnsmasq container image (used in local QEMU/KVM setup). Note : These are just suggestions. Your network administrator or system administrator should choose the right network setup for your company.","title":"Network setup"},{"location":"network-setup/#requirements","text":"Client hardware must have a network interface which supports PXE or iPXE.","title":"Requirements"},{"location":"network-setup/#goals","text":"Add a DNS name which resolves to a matchbox deploy. Chainload BIOS clients (legacy PXE) to iPXE (undionly.kpxe) Chainload UEFI clients to iPXE (ipxe.efi) Point iPXE clients to http://matchbox.example.com:port/boot.ipxe Point GRUB clients to http://matchbox.example.com:port/grub","title":"Goals"},{"location":"network-setup/#setup","text":"Many companies already have DHCP/TFTP configured to \"PXE-boot\" PXE/iPXE clients. In this case, machines (or a subset of machines) can be made to chainload from chain http://matchbox.example.com:port/boot.ipxe . Older PXE clients can be made to chainload into iPXE to be able to fetch subsequent configs via HTTP. On simpler networks, such as what a developer might have at home, a relatively inflexible DHCP server may be in place, with no TFTP server. In this case, a proxy DHCP server can be run alongside a non-PXE capable DHCP server. This diagram can point you to the right section(s) of this document. The setup of DHCP, TFTP, and DNS services on a network varies greatly. If you wish to use Docker to quickly run DHCP, proxyDHCP TFTP, or DNS services, use poseidon/dnsmasq .","title":"Setup"},{"location":"network-setup/#dns","text":"Add a DNS entry (e.g. matchbox.example.com , provisoner.mycompany-internal ) that resolves to a deployment of the CoreOS matchbox service from machines you intend to boot and provision. $ dig matchbox.example.com If you deployed matchbox to a known IP address (e.g. dedicated host, load balanced endpoint, Kubernetes NodePort) and use dnsmasq , a domain name to IPv4/IPv6 address mapping could be added to the /etc/dnsmasq.conf . # dnsmasq.conf address=/matchbox.example.com/172.18.0.2","title":"DNS"},{"location":"network-setup/#ipxe","text":"Networks which already run DHCP and TFTP services to network boot PXE/iPXE clients can add an iPXE config to delegate or chain to the matchbox service's iPXE entrypoint. # /var/www/html/ipxe/default.ipxe chain http://matchbox.example.com:8080/boot.ipxe You can chainload from a menu entry or use other iPXE commands if you need to do more than simple delegation.","title":"iPXE"},{"location":"network-setup/#pxe-enabled-dhcp","text":"Configure your DHCP server to supply options to older PXE client firmware to specify the location of an iPXE or GRUB network boot program on your TFTP server. Send clients to the matchbox iPXE script or GRUB config endpoints. Here is an example /etc/dnsmasq.conf : dhcp-range = 192.168.1.1,192.168.1.254,30m enable-tftp tftp-root = /var/lib/tftpboot # Legacy PXE dhcp-match = set:bios,option:client-arch,0 dhcp-boot = tag:bios,undionly.kpxe # UEFI dhcp-match = set:efi32,option:client-arch,6 dhcp-boot = tag:efi32,ipxe.efi dhcp-match = set:efibc,option:client-arch,7 dhcp-boot = tag:efibc,ipxe.efi dhcp-match = set:efi64,option:client-arch,9 dhcp-boot = tag:efi64,ipxe.efi # iPXE - chainload to matchbox ipxe boot script dhcp-userclass = set:ipxe,iPXE dhcp-boot = tag:ipxe,http://matchbox.example.com:8080/boot.ipxe # verbose log-queries log-dhcp # static DNS assignments address = /matchbox.example.com/192.168.1.100 # (optional) disable DNS and specify alternate # port=0 # dhcp-option=6,192.168.1.100 Add ipxe.efi and unidonly.kpxe to your tftp-root (e.g. /var/lib/tftpboot ). $ sudo systemctl start dnsmasq $ sudo firewall-cmd --add-service = dhcp --add-service = tftp [ --add-service = dns ] $ sudo firewall-cmd --list-services See dnsmasq below to run dnsmasq with a container.","title":"PXE-enabled DHCP"},{"location":"network-setup/#proxy-dhcp","text":"Alternately, a proxy-DHCP server can be run alongside an existing non-PXE DHCP server. The proxy DHCP server provides only the next server and boot filename Options, leaving IP allocation to the DHCP server. Clients listen for both DHCP offers and merge the responses as though they had come from one PXE-enabled DHCP server. Example /etc/dnsmasq.conf : dhcp-range = 192.168.1.1,proxy,255.255.255.0 enable-tftp tftp-root = /var/lib/tftpboot # if request comes from older PXE ROM, chainload to iPXE (via TFTP) pxe-service = tag:#ipxe,x86PC,\"PXE chainload to iPXE\",undionly.kpxe # if request comes from iPXE user class, set tag \"ipxe\" dhcp-userclass = set:ipxe,iPXE # point ipxe tagged requests to the matchbox iPXE boot script (via HTTP) pxe-service = tag:ipxe,x86PC,\"iPXE\",http://matchbox.example.com:8080/boot.ipxe # verbose log-queries log-dhcp Add unidonly.kpxe (and undionly.kpxe.0 if using dnsmasq) to your tftp-root (e.g. /var/lib/tftpboot ). $ sudo systemctl start dnsmasq $ sudo firewall-cmd --add-service = dhcp --add-service = tftp [ --add-service = dns ] $ sudo firewall-cmd --list-services See dnsmasq below to run dnsmasq with a container.","title":"Proxy-DHCP"},{"location":"network-setup/#configurable-tftp","text":"If your DHCP server is configured to network boot PXE clients (but not iPXE clients), add a pxelinux.cfg to serve an iPXE kernel image and append commands. Example /var/lib/tftpboot/pxelinux.cfg/default : timeout 10 default iPXE LABEL iPXE KERNEL ipxe.lkrn APPEND dhcp && chain http://matchbox.example.com:8080/boot.ipxe Add ipxe.lkrn to /var/lib/tftpboot (see iPXE docs ).","title":"Configurable TFTP"},{"location":"network-setup/#poseidondnsmasq","text":"The quay.io/poseidon/dnsmasq container image can run DHCP, TFTP, and DNS services via docker. The image bundles ipxe.efi , undionly.kpxe , and grub.efi for convenience. See contrib/dnsmasq for details. Run DHCP, TFTP, and DNS on the host's network: sudo docker run --rm --cap-add = NET_ADMIN --net = host quay.io/poseidon/dnsmasq \\ -d -q \\ --dhcp-range = 192 .168.1.3,192.168.1.254 \\ --enable-tftp --tftp-root = /var/lib/tftpboot \\ --dhcp-match = set:bios,option:client-arch,0 \\ --dhcp-boot = tag:bios,undionly.kpxe \\ --dhcp-match = set:efi32,option:client-arch,6 \\ --dhcp-boot = tag:efi32,ipxe.efi \\ --dhcp-match = set:efibc,option:client-arch,7 \\ --dhcp-boot = tag:efibc,ipxe.efi \\ --dhcp-match = set:efi64,option:client-arch,9 \\ --dhcp-boot = tag:efi64,ipxe.efi \\ --dhcp-userclass = set:ipxe,iPXE \\ --dhcp-boot = tag:ipxe,http://matchbox.example.com:8080/boot.ipxe \\ --address = /matchbox.example.com/192.168.1.2 \\ --log-queries \\ --log-dhcp Run a proxy-DHCP and TFTP service on the host's network: sudo docker run --rm --cap-add = NET_ADMIN --net = host quay.io/poseidon/dnsmasq \\ -d -q \\ --dhcp-range = 192 .168.1.1,proxy,255.255.255.0 \\ --enable-tftp --tftp-root = /var/lib/tftpboot \\ --dhcp-userclass = set:ipxe,iPXE \\ --pxe-service = tag:#ipxe,x86PC, \"PXE chainload to iPXE\" ,undionly.kpxe \\ --pxe-service = tag:ipxe,x86PC, \"iPXE\" ,http://matchbox.example.com:8080/boot.ipxe \\ --pxe-service = tag:#ipxe,X86-64_EFI, \"PXE chainload to iPXE UEFI\" ,ipxe.efi \\ --pxe-service = tag:ipxe,X86-64_EFI, \"iPXE UEFI\" ,http:///matchbox.example.com:8080/boot.ipxe \\ --log-queries \\ --log-dhcp Be sure to allow enabled services in your firewall configuration. $ sudo firewall-cmd --add-service = dhcp --add-service = tftp --add-service = dns","title":"poseidon/dnsmasq"},{"location":"network-setup/#uefi","text":"","title":"UEFI"},{"location":"network-setup/#development","text":"Install the dependencies for QEMU with UEFI . Walk through the getting-started-with-docker tutorial. Launch client VMs using create-uefi . Create UEFI QEMU/KVM VMs attached to the docker0 bridge. $ sudo ./scripts/libvirt create-uefi UEFI clients should chainload ipxe.efi , load iPXE and Ignition configs from Matchbox, and Container Linux should boot as usual.","title":"Development"},{"location":"network-setup/#troubleshooting","text":"See troubleshooting .","title":"Troubleshooting"},{"location":"openpgp/","text":"OpenPGP signing \u00b6 The matchbox OpenPGP signature endpoints serve detached binary and ASCII armored signatures of rendered configs, if enabled. Each config endpoint has corresponding signature endpoints, typically suffixed with .sig or .asc . To enable OpenPGP signing, provide the path to a secret keyring containing a single signing key with -key-ring-path or by setting MATCHBOX_KEY_RING_PATH . If a passphrase is required, set it via the MATCHBOX_PASSPHRASE environment variable. Here are example signature endpoints without their query parameters. Endpoint Signature Endpoint ASCII Signature Endpoint iPXE http://matchbox.foo/ipxe.sig http://matchbox.foo/ipxe.asc GRUB2 http://bootcf.foo/grub.sig http://matchbox.foo/grub.asc Ignition http://matchbox.foo/ignition.sig http://matchbox.foo/ignition.asc Cloud-Config http://matchbox.foo/cloud.sig http://matchbox.foo/cloud.asc Metadata http://matchbox.foo/metadata.sig http://matchbox.foo/metadata.asc In production, mount your signing keyring and source the passphrase from a Kubernetes secret . Use a signing subkey exported to a keyring by itself, which can be revoked by a primary key, if needed. To try it locally, you may use the test fixture keyring. Warning: The test fixture keyring is for examples only. Verify \u00b6 Verify a signature response and config response from the command line using the public key. Notice that most configs have a trailing newline. Warning: The test fixture keyring is for examples only. $ gpg --homedir sign/fixtures --verify sig_file response_file gpg: Signature made Mon 08 Feb 2016 11 :37:03 PM PST using RSA key ID 9896356A gpg: sign/fixtures/trustdb.gpg: trustdb created gpg: Good signature from \"Fake Bare Metal Key (Do not use) <do-not-use@example.com>\" gpg: WARNING: This key is not certified with a trusted signature! gpg: There is no indication that the signature belongs to the owner. Primary key fingerprint: BE2F 12BC 3642 2594 570A CCBB 8DC4 2020 9896 356A Signing key generation \u00b6 Create a signing key or subkey according to your requirements and security policies. Here are some basic guides . gpg \u00b6 $ mkdir -m 700 path/in/vault $ gpg --homedir path/in/vault --expert --gen-key ... gpg2 \u00b6 $ mkdir -m 700 path/in/vault $ gpg2 --homedir path/in/vault --expert --gen-key ... $ gpg2 --homedir path/in/vault --export-secret-key KEYID > path/in/vault/secring.gpg","title":"OpenPGP Signing"},{"location":"openpgp/#openpgp-signing","text":"The matchbox OpenPGP signature endpoints serve detached binary and ASCII armored signatures of rendered configs, if enabled. Each config endpoint has corresponding signature endpoints, typically suffixed with .sig or .asc . To enable OpenPGP signing, provide the path to a secret keyring containing a single signing key with -key-ring-path or by setting MATCHBOX_KEY_RING_PATH . If a passphrase is required, set it via the MATCHBOX_PASSPHRASE environment variable. Here are example signature endpoints without their query parameters. Endpoint Signature Endpoint ASCII Signature Endpoint iPXE http://matchbox.foo/ipxe.sig http://matchbox.foo/ipxe.asc GRUB2 http://bootcf.foo/grub.sig http://matchbox.foo/grub.asc Ignition http://matchbox.foo/ignition.sig http://matchbox.foo/ignition.asc Cloud-Config http://matchbox.foo/cloud.sig http://matchbox.foo/cloud.asc Metadata http://matchbox.foo/metadata.sig http://matchbox.foo/metadata.asc In production, mount your signing keyring and source the passphrase from a Kubernetes secret . Use a signing subkey exported to a keyring by itself, which can be revoked by a primary key, if needed. To try it locally, you may use the test fixture keyring. Warning: The test fixture keyring is for examples only.","title":"OpenPGP signing"},{"location":"openpgp/#verify","text":"Verify a signature response and config response from the command line using the public key. Notice that most configs have a trailing newline. Warning: The test fixture keyring is for examples only. $ gpg --homedir sign/fixtures --verify sig_file response_file gpg: Signature made Mon 08 Feb 2016 11 :37:03 PM PST using RSA key ID 9896356A gpg: sign/fixtures/trustdb.gpg: trustdb created gpg: Good signature from \"Fake Bare Metal Key (Do not use) <do-not-use@example.com>\" gpg: WARNING: This key is not certified with a trusted signature! gpg: There is no indication that the signature belongs to the owner. Primary key fingerprint: BE2F 12BC 3642 2594 570A CCBB 8DC4 2020 9896 356A","title":"Verify"},{"location":"openpgp/#signing-key-generation","text":"Create a signing key or subkey according to your requirements and security policies. Here are some basic guides .","title":"Signing key generation"},{"location":"openpgp/#gpg","text":"$ mkdir -m 700 path/in/vault $ gpg --homedir path/in/vault --expert --gen-key ...","title":"gpg"},{"location":"openpgp/#gpg2","text":"$ mkdir -m 700 path/in/vault $ gpg2 --homedir path/in/vault --expert --gen-key ... $ gpg2 --homedir path/in/vault --export-secret-key KEYID > path/in/vault/secring.gpg","title":"gpg2"},{"location":"troubleshooting/","text":"Troubleshooting \u00b6 Firewall \u00b6 Running DHCP or proxyDHCP with poseidon/dnsmasq on a host requires that the Firewall allow DHCP and TFTP (for chainloading) services to run. Port collision \u00b6 Running DHCP or proxyDHCP can cause port already in use collisions depending on what's running. Fedora runs bootp listening on udp/67 for example. Find the service using the port. $ sudo lsof -i :67 Evaluate whether you can configure the existing service or whether you'd like to stop it and test with poseidon/dnsmasq . No boot filename received \u00b6 PXE client firmware did not receive a DHCP Offer with PXE-Options after several attempts. If you're using the poseidon/dnsmasq image with -d , each request should log to stdout. Using the wrong -i interface is the most common reason DHCP requests are not received. Otherwise, wireshark can be useful for investigating.","title":"Troubleshooting"},{"location":"troubleshooting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"troubleshooting/#firewall","text":"Running DHCP or proxyDHCP with poseidon/dnsmasq on a host requires that the Firewall allow DHCP and TFTP (for chainloading) services to run.","title":"Firewall"},{"location":"troubleshooting/#port-collision","text":"Running DHCP or proxyDHCP can cause port already in use collisions depending on what's running. Fedora runs bootp listening on udp/67 for example. Find the service using the port. $ sudo lsof -i :67 Evaluate whether you can configure the existing service or whether you'd like to stop it and test with poseidon/dnsmasq .","title":"Port collision"},{"location":"troubleshooting/#no-boot-filename-received","text":"PXE client firmware did not receive a DHCP Offer with PXE-Options after several attempts. If you're using the poseidon/dnsmasq image with -d , each request should log to stdout. Using the wrong -i interface is the most common reason DHCP requests are not received. Otherwise, wireshark can be useful for investigating.","title":"No boot filename received"},{"location":"dev/develop/","text":"Development \u00b6 To develop matchbox locally, compile the binary and build the container image. Static binary \u00b6 Build the static binary. $ make build Test with vendored dependencies. $ make test Container image \u00b6 Build a container image coreos/matchbox:latest . $ make docker-image Version \u00b6 $ ./bin/matchbox -version $ sudo docker run coreos/matchbox:latest -version Run \u00b6 Run the binary. $ ./bin/matchbox -address = 0 .0.0.0:8080 -log-level = debug -data-path examples -assets-path examples/assets Run the Docker image on docker0 . $ sudo docker run -p 8080 :8080 --rm -v $PWD /examples:/var/lib/matchbox:Z -v $PWD /examples/groups/etcd:/var/lib/matchbox/groups:Z coreos/matchbox:latest -address = 0 .0.0.0:8080 -log-level = debug bootcmd \u00b6 Run bootcmd against the gRPC API of the service. $ ./bin/bootcmd profile list --endpoints 172 .18.0.2:8081 --cacert examples/etc/matchbox/ca.crt Vendor \u00b6 Add or update dependencies in go.mod and vendor. make update make vendor Codegen \u00b6 Generate code from proto definitions using protoc and the protoc-gen-go plugin. $ make codegen","title":"Development"},{"location":"dev/develop/#development","text":"To develop matchbox locally, compile the binary and build the container image.","title":"Development"},{"location":"dev/develop/#static-binary","text":"Build the static binary. $ make build Test with vendored dependencies. $ make test","title":"Static binary"},{"location":"dev/develop/#container-image","text":"Build a container image coreos/matchbox:latest . $ make docker-image","title":"Container image"},{"location":"dev/develop/#version","text":"$ ./bin/matchbox -version $ sudo docker run coreos/matchbox:latest -version","title":"Version"},{"location":"dev/develop/#run","text":"Run the binary. $ ./bin/matchbox -address = 0 .0.0.0:8080 -log-level = debug -data-path examples -assets-path examples/assets Run the Docker image on docker0 . $ sudo docker run -p 8080 :8080 --rm -v $PWD /examples:/var/lib/matchbox:Z -v $PWD /examples/groups/etcd:/var/lib/matchbox/groups:Z coreos/matchbox:latest -address = 0 .0.0.0:8080 -log-level = debug","title":"Run"},{"location":"dev/develop/#bootcmd","text":"Run bootcmd against the gRPC API of the service. $ ./bin/bootcmd profile list --endpoints 172 .18.0.2:8081 --cacert examples/etc/matchbox/ca.crt","title":"bootcmd"},{"location":"dev/develop/#vendor","text":"Add or update dependencies in go.mod and vendor. make update make vendor","title":"Vendor"},{"location":"dev/develop/#codegen","text":"Generate code from proto definitions using protoc and the protoc-gen-go plugin. $ make codegen","title":"Codegen"},{"location":"dev/release/","text":"Release guide \u00b6 This guide covers releasing new versions of matchbox. Version \u00b6 Create a release commit which updates old version references. $ export VERSION = v0.9.0 Tag \u00b6 Tag, sign the release version, and push it to Github. $ git tag -s vX.Y.Z -m 'vX.Y.Z' $ git push origin --tags $ git push origin master Images \u00b6 Travis CI will build the Docker image and push it to Quay.io when the tag is pushed to master. Verify the new image and version. $ sudo docker run quay.io/poseidon/matchbox: $VERSION -version Github release \u00b6 Publish the release on Github with release notes. Tarballs \u00b6 Build the release tarballs. $ make release Verify the reported version. ./_output/matchbox-v0.9.0-linux-amd64/matchbox -version Signing \u00b6 Release tarballs are signed by Dalton Hubble's GPG Key cd _output gpg2 --armor --detach-sign matchbox- $VERSION -linux-amd64.tar.gz gpg2 --armor --detach-sign matchbox- $VERSION -darwin-amd64.tar.gz gpg2 --armor --detach-sign matchbox- $VERSION -linux-arm.tar.gz gpg2 --armor --detach-sign matchbox- $VERSION -linux-arm64.tar.gz Verify the signatures. gpg2 --verify matchbox- $VERSION -linux-amd64.tar.gz.asc matchbox- $VERSION -linux-amd64.tar.gz gpg2 --verify matchbox- $VERSION -darwin-amd64.tar.gz.asc matchbox- $VERSION -darwin-amd64.tar.gz gpg2 --verify matchbox- $VERSION -linux-arm.tar.gz.asc matchbox- $VERSION -linux-arm.tar.gz gpg2 --verify matchbox- $VERSION -linux-arm64.tar.gz.asc matchbox- $VERSION -linux-arm64.tar.gz Publish \u00b6 Upload the signed tarball(s) with the Github release. Promote the release from a pre-release to an official release.","title":"Release guide"},{"location":"dev/release/#release-guide","text":"This guide covers releasing new versions of matchbox.","title":"Release guide"},{"location":"dev/release/#version","text":"Create a release commit which updates old version references. $ export VERSION = v0.9.0","title":"Version"},{"location":"dev/release/#tag","text":"Tag, sign the release version, and push it to Github. $ git tag -s vX.Y.Z -m 'vX.Y.Z' $ git push origin --tags $ git push origin master","title":"Tag"},{"location":"dev/release/#images","text":"Travis CI will build the Docker image and push it to Quay.io when the tag is pushed to master. Verify the new image and version. $ sudo docker run quay.io/poseidon/matchbox: $VERSION -version","title":"Images"},{"location":"dev/release/#github-release","text":"Publish the release on Github with release notes.","title":"Github release"},{"location":"dev/release/#tarballs","text":"Build the release tarballs. $ make release Verify the reported version. ./_output/matchbox-v0.9.0-linux-amd64/matchbox -version","title":"Tarballs"},{"location":"dev/release/#signing","text":"Release tarballs are signed by Dalton Hubble's GPG Key cd _output gpg2 --armor --detach-sign matchbox- $VERSION -linux-amd64.tar.gz gpg2 --armor --detach-sign matchbox- $VERSION -darwin-amd64.tar.gz gpg2 --armor --detach-sign matchbox- $VERSION -linux-arm.tar.gz gpg2 --armor --detach-sign matchbox- $VERSION -linux-arm64.tar.gz Verify the signatures. gpg2 --verify matchbox- $VERSION -linux-amd64.tar.gz.asc matchbox- $VERSION -linux-amd64.tar.gz gpg2 --verify matchbox- $VERSION -darwin-amd64.tar.gz.asc matchbox- $VERSION -darwin-amd64.tar.gz gpg2 --verify matchbox- $VERSION -linux-arm.tar.gz.asc matchbox- $VERSION -linux-arm.tar.gz gpg2 --verify matchbox- $VERSION -linux-arm64.tar.gz.asc matchbox- $VERSION -linux-arm64.tar.gz","title":"Signing"},{"location":"dev/release/#publish","text":"Upload the signed tarball(s) with the Github release. Promote the release from a pre-release to an official release.","title":"Publish"}]}